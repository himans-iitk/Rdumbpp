{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1819e31",
      "metadata": {},
      "source": [
        "# CCC Evaluation: Complete Results Generation\n",
        "\n",
        "Generate results for 1M images per seed across 3 speeds, including ablations.\n",
        "\n",
        "## Models\n",
        "- Baseline (pretrained)\n",
        "- RDumb\n",
        "- RDumb++: EntropyFull, EntropySoft, KLFull, KLSoft\n",
        "\n",
        "## Ablations\n",
        "- Drift threshold k: 2.0, 2.5, 3.0\n",
        "- Soft reset strength λ: 0.30, 0.50, 0.70\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0151b67e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "python_version = sys.version_info\n",
        "print(f\"Python {python_version.major}.{python_version.minor}\")\n",
        "\n",
        "if python_version.major == 3 and python_version.minor >= 9:\n",
        "    print(\"Version OK\")\n",
        "else:\n",
        "    print(\"Warning: Python 3.9+ recommended\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f658c523",
      "metadata": {},
      "source": [
        "## Clone Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d2c940",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "base_dir = os.getcwd()\n",
        "if os.path.basename(base_dir) == \"CCC\":\n",
        "    base_dir = os.path.dirname(base_dir)\n",
        "\n",
        "repo_path = os.path.join(base_dir, \"CCC\")\n",
        "\n",
        "if not os.path.exists(repo_path):\n",
        "    subprocess.run([\"git\", \"clone\", \"https://github.com/oripress/CCC.git\"], cwd=base_dir, check=True)\n",
        "\n",
        "os.chdir(repo_path)\n",
        "print(f\"Directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7521c81d",
      "metadata": {},
      "source": [
        "##  GPU Setup and Installation\n",
        "### Automatic CUDA Version Handling\n",
        "- **Works with any GPU:** RTX 4000, RTX 5090, A100, V100, etc.\n",
        "- **Automatic detection:** Detects your PyTorch CUDA version automatically\n",
        "- **Auto-fix:** Automatically installs matching torchvision version\n",
        "- **No manual config:** You don't need to specify CUDA versions\n",
        "**If you switch GPUs or systems:** Just run the cells from the start - the notebook will automatically detect and fix any CUDA version mismatches.\n",
        "**Then run the cell below on RunPod to setup GPU.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a937cb1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SINGLE CELL: GPU Setup and Verification\n",
        "# This cell handles everything needed to connect to GPU\n",
        "# ============================================================================\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import platform\n",
        "\n",
        "\n",
        "# Step 0: Check if running on correct system\n",
        "system = platform.system()\n",
        "hostname = platform.node()\n",
        "python_path = sys.executable\n",
        "\n",
        "print(f\"  System: {system}\")\n",
        "print(f\"  Hostname: {hostname}\")\n",
        "print(f\"  Python: {python_path}\")\n",
        "\n",
        "# Check if running on Mac (local) vs Linux (RunPod)\n",
        "if system == \"Darwin\" or \"miniconda3\" in python_path or \"Users\" in python_path:\n",
        "    print(\"\\nTo fix this:\")\n",
        "    print(\"  1. SSH into RunPod:\")\n",
        "    print(\"     ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
        "    print(\"\\n  2. On RunPod, start Jupyter:\")\n",
        "    print(\"     pip install jupyter\")\n",
        "    print(\"\\n  3. Access from your Mac using port forwarding:\")\n",
        "    print(\"     ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
        "    print(\"     Then open http://localhost:8888 in browser\")\n",
        "    print(\"\\n  4. Upload this notebook to RunPod and run it there\")\n",
        "    raise RuntimeError(\"Cannot install CUDA PyTorch on Mac. Please run on RunPod.\")\n",
        "\n",
        "# Step 1: Check GPU Hardware\n",
        "try:\n",
        "    result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,driver_version\", \"--format=csv,noheader\"], \n",
        "                           capture_output=True, text=True, timeout=10)\n",
        "    if result.returncode == 0:\n",
        "        gpu_info = result.stdout.strip().split('\\n')[0]\n",
        "        print(f\"   GPU detected: {gpu_info}\")\n",
        "        gpu_available = True\n",
        "    else:\n",
        "        print(\"   nvidia-smi not available\")\n",
        "        gpu_available = False\n",
        "except Exception as e:\n",
        "    print(f\"   Could not check GPU: {e}\")\n",
        "    gpu_available = False\n",
        "\n",
        "# Step 2: Check Python Environment\n",
        "print(f\"\\n[Step 2] Python Environment:\")\n",
        "print(f\"  Python: {sys.executable}\")\n",
        "print(f\"  Version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Step 3: Check Current PyTorch Installation\n",
        "print(f\"\\n[Step 3] Checking Current PyTorch Installation...\")\n",
        "need_install = False  # Initialize variable\n",
        "torch_installed = False\n",
        "cuda_available = False\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    torch_installed = True\n",
        "    print(f\"   PyTorch version: {torch.__version__}\")\n",
        "    print(f\"   PyTorch location: {torch.__file__}\")\n",
        "    \n",
        "    # Check for CUDA version mismatch\n",
        "    try:\n",
        "        import torchvision\n",
        "        print(f\"   Torchvision version: {torchvision.__version__}\")\n",
        "        \n",
        "        # Try to check CUDA versions\n",
        "        try:\n",
        "            torch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
        "            # This might raise an error if versions don't match\n",
        "            cuda_available = torch.cuda.is_available()\n",
        "            \n",
        "            if cuda_available:\n",
        "                print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "                print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "                \n",
        "                # Test if there's a version mismatch by trying to use torchvision\n",
        "                try:\n",
        "                    test_img = torchvision.transforms.ToTensor()(torch.zeros(3, 224, 224))\n",
        "                    print(\"\\nYou can proceed with evaluation. No installation needed.\")\n",
        "                    need_install = False\n",
        "                except RuntimeError as e:\n",
        "                    if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
        "                        print(\"   CUDA version mismatch detected!\")\n",
        "                        print(f\"  Error: {e}\")\n",
        "                        print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
        "                        need_install = True\n",
        "                    else:\n",
        "                        raise\n",
        "            else:\n",
        "                print(\"   CUDA not available - need to install CUDA PyTorch\")\n",
        "                need_install = True\n",
        "        except RuntimeError as e:\n",
        "            if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
        "                print(\"   CUDA version mismatch detected!\")\n",
        "                print(f\"  Error: {e}\")\n",
        "                print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
        "                need_install = True\n",
        "            else:\n",
        "                print(f\"   Error checking CUDA: {e}\")\n",
        "                need_install = True\n",
        "    except ImportError:\n",
        "        print(\"   Torchvision not installed\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"  PyTorch has CUDA but torchvision missing - will install\")\n",
        "            need_install = True\n",
        "        else:\n",
        "            need_install = True\n",
        "            \n",
        "except ImportError:\n",
        "    print(\"   PyTorch not installed\")\n",
        "    need_install = True\n",
        "    torch_installed = False\n",
        "\n",
        "# Step 4: Install CUDA PyTorch if needed\n",
        "if need_install:\n",
        "    print(f\"\\n[Step 4] Installing CUDA-enabled PyTorch...\")\n",
        "    print(\"  This will install PyTorch 2.0.1 with CUDA 11.8 support\")\n",
        "    print(\"  (CUDA 11.8 is compatible with CUDA 12.x systems)\")\n",
        "    \n",
        "    # Uninstall existing PyTorch first\n",
        "    if torch_installed:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"-y\", \"-q\"], \n",
        "                      check=False, capture_output=True)\n",
        "    \n",
        "    # Install NumPy first (required)\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"], \n",
        "                      check=True, capture_output=True, timeout=60)\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Check if we just need to fix torchvision version mismatch\n",
        "    if torch_installed and cuda_available:\n",
        "        print(\"  Fixing CUDA version mismatch...\")\n",
        "        try:\n",
        "            # Uninstall torchvision first\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
        "                          check=False, capture_output=True)\n",
        "            # Reinstall torchvision matching PyTorch's CUDA version\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
        "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
        "                check=True,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "            success = True\n",
        "        except Exception as e:\n",
        "            print(f\"     Failed to fix version mismatch: {str(e)[:100]}\")\n",
        "            print(\"    Will try full reinstall...\")\n",
        "            success = False\n",
        "    else:\n",
        "        success = False\n",
        "    \n",
        "    # Install CUDA PyTorch - try multiple methods\n",
        "    if not success:\n",
        "        \n",
        "        # Method 1: Using --index-url (recommended)\n",
        "        try:\n",
        "            print(\"    Trying method 1: --index-url...\")\n",
        "            result = subprocess.run(\n",
        "                [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
        "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
        "                check=True,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=600\n",
        "            )\n",
        "            success = True\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"     Timeout - trying alternative method...\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"     Failed: {str(e)[:100]}\")\n",
        "            print(\"    Trying alternative method...\")\n",
        "        \n",
        "        # Method 2: Using extra-index-url\n",
        "        if not success:\n",
        "            try:\n",
        "                print(\"    Trying method 2: --extra-index-url...\")\n",
        "                result = subprocess.run(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
        "                     \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
        "                    check=True,\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=600\n",
        "                )\n",
        "                success = True\n",
        "            except Exception as e:\n",
        "                print(f\"     Failed: {str(e)[:100]}\")\n",
        "        \n",
        "        # Method 3: Install separately to ensure matching versions\n",
        "        if not success:\n",
        "            print(\"    Trying method 3: Separate installation...\")\n",
        "            try:\n",
        "                # Install PyTorch first\n",
        "                subprocess.run(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\",\n",
        "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
        "                    check=True,\n",
        "                    capture_output=True,\n",
        "                    timeout=300\n",
        "                )\n",
        "                # Then install matching torchvision\n",
        "                subprocess.run(\n",
        "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
        "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
        "                    check=True,\n",
        "                    capture_output=True,\n",
        "                    timeout=300\n",
        "                )\n",
        "                success = True\n",
        "            except Exception as e:\n",
        "                print(f\"     Failed: {str(e)[:100]}\")\n",
        "    \n",
        "    if not success:\n",
        "        print(\" INSTALLATION FAILED\")\n",
        "        print(\"\\nPlease install manually in terminal:\")\n",
        "        print(f\"  {sys.executable} -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
        "        print(\"\\nThen restart kernel and run this cell again.\")\n",
        "        raise RuntimeError(\"CUDA PyTorch installation failed\")\n",
        "    \n",
        "    print(\"   IMPORTANT: Restarting kernel to load new PyTorch...\")\n",
        "    print(\"  (You may need to manually restart: Kernel → Restart)\")\n",
        "\n",
        "# Step 5: Final Verification\n",
        "print(f\"\\n[Step 5] Final GPU Verification...\")\n",
        "print(\"  (If you just installed, restart kernel first!)\")\n",
        "\n",
        "try:\n",
        "    # Force reload if just installed\n",
        "    if need_install:\n",
        "        import importlib\n",
        "        if 'torch' in sys.modules:\n",
        "            importlib.reload(sys.modules['torch'])\n",
        "    \n",
        "    import torch\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    \n",
        "    if cuda_available:\n",
        "        print(f\"   CUDA available: True\")\n",
        "        print(f\"   CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   Number of GPUs: {torch.cuda.device_count()}\")\n",
        "        \n",
        "        # Test GPU with actual computation\n",
        "        try:\n",
        "            test_tensor = torch.randn(100, 100).cuda()\n",
        "            result = test_tensor @ test_tensor\n",
        "        except Exception as e:\n",
        "            print(f\"   GPU computation test failed: {e}\")\n",
        "            raise\n",
        "        \n",
        "        print(\" CUDA PyTorch installed\")\n",
        "        print(\"\\nYou can now proceed with evaluation cells.\")\n",
        "    else:\n",
        "        print(\"   CUDA still not available\")\n",
        "        print(\"\\nPossible issues:\")\n",
        "        print(\"  1. Kernel not restarted after installation\")\n",
        "        print(\"     → Go to: Kernel → Restart & Clear Output\")\n",
        "        print(\"     → Then run this cell again\")\n",
        "        print(\"\\n  2. Python environment mismatch\")\n",
        "        print(f\"     → Terminal Python: Check with 'which python3'\")\n",
        "        print(f\"     → Notebook Python: {sys.executable}\")\n",
        "        print(\"     → They should match!\")\n",
        "        print(\"\\n  3. CUDA libraries not found\")\n",
        "        print(\"     → Check: ls /usr/local/cuda*/lib64\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"   Error during verification: {e}\")\n",
        "    print(\"\\nPlease restart kernel and run this cell again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "148d2d12",
      "metadata": {},
      "source": [
        "##  IMPORTANT: GPU Detection\n",
        "**If you installed CUDA PyTorch in the terminal, you MUST restart the Jupyter kernel!**\n",
        "The kernel needs to be restarted to load the new CUDA-enabled PyTorch. Otherwise, it will still use the old CPU version that was loaded into memory.\n",
        "**To restart:** Go to `Kernel` → `Restart` (or `Restart & Clear Output`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8742e6",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set parameters for evaluation: 1M images per seed, 3 speeds, all models, and ablations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9177aa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "BASELINE = 20\n",
        "SEEDS = [43, 44, 45]\n",
        "SPEEDS = [1000, 2000, 5000]\n",
        "\n",
        "MODELS = {\n",
        "    \"Baseline\": \"pretrained\",\n",
        "    \"RDumb\": \"rdumb\",\n",
        "    \"EntropyFull\": \"rdumbpp_ent_full\",\n",
        "    \"EntropySoft\": \"rdumbpp_ent_soft\",\n",
        "    \"KLFull\": \"rdumbpp_kl_full\",\n",
        "    \"KLSoft\": \"rdumbpp_kl_soft\",\n",
        "}\n",
        "\n",
        "K_VALUES = [2.0, 2.5, 3.0]\n",
        "LAMBDA_VALUES = [0.30, 0.50, 0.70]\n",
        "\n",
        "print(f\"Baseline: {BASELINE}\")\n",
        "print(f\"Seeds: {SEEDS}\")\n",
        "print(f\"Speeds: {SPEEDS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4af8578",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_evaluation(mode, baseline, seed, speed, drift_k=2.5, lambda_soft=0.5):\n",
        "    processind = SEEDS.index(seed) + (SPEEDS.index(speed) * 3)\n",
        "    \n",
        "    cmd = [sys.executable, \"eval.py\",\n",
        "           \"--mode\", mode,\n",
        "           \"--baseline\", str(baseline),\n",
        "           \"--logs\", \"logs\",\n",
        "           \"--processind\", str(processind),\n",
        "           \"--dset\", \"\"]\n",
        "    \n",
        "    if mode.startswith(\"rdumbpp_\"):\n",
        "        cmd.extend([\n",
        "            \"--drift_k\", str(drift_k),\n",
        "            \"--lambda_soft\", str(lambda_soft),\n",
        "            \"--warmup\", \"50\",\n",
        "            \"--cooldown\", \"200\",\n",
        "            \"--ent_alpha\", \"0.99\",\n",
        "            \"--kl_alpha\", \"0.99\",\n",
        "        ])\n",
        "    \n",
        "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)\n",
        "    return result.returncode == 0\n",
        "\n",
        "def calculate_accuracy(result_file):\n",
        "    if not os.path.exists(result_file):\n",
        "        return None\n",
        "    accuracies = []\n",
        "    with open(result_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.strip().startswith('acc_'):\n",
        "                try:\n",
        "                    acc = float(line.strip().split('_')[1])\n",
        "                    accuracies.append(acc)\n",
        "                except:\n",
        "                    pass\n",
        "    return np.mean(accuracies) if accuracies else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9fe7f18",
      "metadata": {},
      "source": [
        "## Main Evaluation: All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6c3bbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = defaultdict(dict)\n",
        "\n",
        "for model_name, mode in MODELS.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for seed in SEEDS:\n",
        "        for speed in SPEEDS:\n",
        "            drift_k = 2.5 if mode.startswith(\"rdumbpp_\") else None\n",
        "            lambda_soft = 0.5 if mode.startswith(\"rdumbpp_\") else None\n",
        "            \n",
        "            success = run_evaluation(mode, BASELINE, seed, speed, \n",
        "                                   drift_k=drift_k, lambda_soft=lambda_soft)\n",
        "            \n",
        "            if success:\n",
        "                result_file = os.path.join(\n",
        "                    \"logs\", f\"ccc_{BASELINE}\",\n",
        "                    f\"model_{mode}_baseline_{BASELINE}_transition+speed_{speed}_seed_{seed}.txt\"\n",
        "                )\n",
        "                acc = calculate_accuracy(result_file)\n",
        "                results[model_name][(seed, speed)] = acc\n",
        "                print(f\"  Seed {seed}, Speed {speed}: {acc:.2f}%\" if acc else f\"  Seed {seed}, Speed {speed}: Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8889cc38",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "Install all required packages with compatible versions. **Important**: We need NumPy < 2.0 for compatibility with torchvision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd40705c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Table 3: Ablation on soft reset strength λ\n",
        "table3_data = [{\"λ\": lam, \"Accuracy (%)\": f\"{ablation_lambda_results[lam]:.1f}\"} \n",
        "               for lam in sorted(ablation_lambda_results.keys())]\n",
        "\n",
        "df_table3 = pd.DataFrame(table3_data)\n",
        "print(\"Table 3: Ablation on soft reset strength λ\")\n",
        "print(\"=\"*60)\n",
        "print(df_table3.to_string(index=False))\n",
        "df_table3.to_csv(\"table3_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34848a56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies with compatible versions\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# First, uninstall existing packages to avoid conflicts\n",
        "try:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"numpy\", \"-y\", \"-q\"], \n",
        "                  check=False, capture_output=True)\n",
        "    print(\"   Cleaned up existing installations\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Install NumPy first (must be < 2.0 for compatibility)\n",
        "try:\n",
        "    subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"],\n",
        "        check=True,\n",
        "        capture_output=True\n",
        "    )\n",
        "    print(\"   NumPy < 2.0 installed\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error installing NumPy: {e}\")\n",
        "\n",
        "# Install PyTorch and torchvision together with compatible versions\n",
        "try:\n",
        "    subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\", \"-q\"],\n",
        "        check=True,\n",
        "        capture_output=True\n",
        "    )\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"   Error with specific versions, trying compatible range...\")\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", \"torch>=2.0.0,<2.1.0\", \"torchvision>=0.15.0,<0.16.0\", \"-q\"],\n",
        "            check=True,\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(\"   PyTorch and torchvision installed (compatible versions)\")\n",
        "    except:\n",
        "        print(\"   Failed to install PyTorch/torchvision\")\n",
        "        raise\n",
        "\n",
        "# Install other dependencies\n",
        "other_packages = [\n",
        "    \"webdataset>=0.2.0\",\n",
        "    \"Pillow>=8.0.0\",\n",
        "]\n",
        "\n",
        "for package in other_packages:\n",
        "    print(f\"  Installing {package}...\")\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"],\n",
        "            check=True,\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(f\"   {package} installed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"   Error installing {package}\")\n",
        "\n",
        "print(\"Dependency installation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a31e2f",
      "metadata": {},
      "source": [
        "## Verify Installations\n",
        "Check that all packages are installed correctly and are compatible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f83141",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3c2bdff3",
      "metadata": {},
      "source": [
        "## Create Logs Directory\n",
        "Create directory for storing evaluation results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fc8c3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify installations and compatibility\n",
        "print(\"Verifying installations...\")\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(f\" PyTorch version: {torch.__version__}\")\n",
        "    pytorch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
        "    if pytorch_cuda:\n",
        "        print(f\" PyTorch CUDA version: {pytorch_cuda}\")\n",
        "except ImportError as e:\n",
        "    print(f\" PyTorch not installed: {e}\")\n",
        "    torch = None\n",
        "    pytorch_cuda = None\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(f\" Torchvision version: {torchvision.__version__}\")\n",
        "    \n",
        "    # Test compatibility by importing models\n",
        "    try:\n",
        "        import torchvision.models as models\n",
        "    except RuntimeError as e:\n",
        "        if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
        "            print(f\" CUDA version mismatch detected: {e}\")\n",
        "            \n",
        "            # Get PyTorch CUDA version\n",
        "            import torch\n",
        "            pytorch_cuda = torch.version.cuda\n",
        "            print(f\"  PyTorch CUDA version: {pytorch_cuda}\")\n",
        "            \n",
        "            # Determine CUDA wheel version\n",
        "            if pytorch_cuda.startswith(\"11.7\"):\n",
        "                cuda_wheel = \"cu117\"\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            elif pytorch_cuda.startswith(\"11.8\"):\n",
        "                cuda_wheel = \"cu118\"\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            elif pytorch_cuda.startswith(\"12.1\"):\n",
        "                cuda_wheel = \"cu121\"\n",
        "                torchvision_version = None  # Use latest\n",
        "            elif pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\"):\n",
        "                cuda_wheel = \"cu124\"\n",
        "                torchvision_version = None  # Use latest\n",
        "            else:\n",
        "                cuda_wheel = \"cu118\"  # Default\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            \n",
        "            # Uninstall torchvision\n",
        "            import subprocess\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
        "                         check=False, capture_output=True)\n",
        "            \n",
        "            # Reinstall matching version\n",
        "            if torchvision_version:\n",
        "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", f\"torchvision=={torchvision_version}\",\n",
        "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "            else:\n",
        "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
        "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "            \n",
        "            try:\n",
        "                result = subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
        "                print(\"   Please restart kernel and run this cell again.\")\n",
        "                print(\"  (Kernel → Restart & Clear Output)\")\n",
        "            except Exception as install_error:\n",
        "                print(f\"   Failed to reinstall: {install_error}\")\n",
        "                print(f\"  Please run manually: {' '.join(install_cmd)}\")\n",
        "        else:\n",
        "            print(f\" Torchvision compatibility issue: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\" Torchvision compatibility issue: {e}\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\" Torchvision not installed: {e}\")\n",
        "except RuntimeError as e:\n",
        "    if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
        "        print(f\" CUDA version mismatch detected: {e}\")\n",
        "        \n",
        "        if torch is not None and pytorch_cuda:\n",
        "            # Determine CUDA wheel version\n",
        "            if pytorch_cuda.startswith(\"11.7\"):\n",
        "                cuda_wheel = \"cu117\"\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            elif pytorch_cuda.startswith(\"11.8\"):\n",
        "                cuda_wheel = \"cu118\"\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            elif pytorch_cuda.startswith(\"12.1\"):\n",
        "                cuda_wheel = \"cu121\"\n",
        "                torchvision_version = None\n",
        "            elif pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\"):\n",
        "                cuda_wheel = \"cu124\"\n",
        "                torchvision_version = None\n",
        "            else:\n",
        "                cuda_wheel = \"cu118\"\n",
        "                torchvision_version = \"0.15.2\"\n",
        "            \n",
        "            # Uninstall and reinstall\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
        "                         check=False, capture_output=True)\n",
        "            \n",
        "            if torchvision_version:\n",
        "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", f\"torchvision=={torchvision_version}\",\n",
        "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "            else:\n",
        "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
        "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "            \n",
        "            try:\n",
        "                result = subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
        "                print(\"   Please restart kernel and run this cell again.\")\n",
        "                print(\"  (Kernel → Restart & Clear Output)\")\n",
        "            except Exception as install_error:\n",
        "                error_msg = install_error.stderr if hasattr(install_error, 'stderr') and install_error.stderr else str(install_error)\n",
        "                print(f\"   Failed to reinstall: {error_msg[:200]}\")\n",
        "                print(f\"  Please run manually: {' '.join(install_cmd)}\")\n",
        "        else:\n",
        "            print(\"  Cannot auto-fix: PyTorch CUDA version not detected\")\n",
        "    else:\n",
        "        print(f\" Error importing torchvision: {e}\")\n",
        "\n",
        "try:\n",
        "    import numpy\n",
        "    print(f\" NumPy version: {numpy.__version__}\")\n",
        "    if numpy.__version__.startswith(\"2.\"):\n",
        "        print(\"  Please downgrade to NumPy < 2.0 by running: pip install 'numpy<2.0'\")\n",
        "except ImportError as e:\n",
        "    print(f\" NumPy not installed: {e}\")\n",
        "\n",
        "try:\n",
        "    import webdataset\n",
        "    print(f\" WebDataset version: {webdataset.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\" WebDataset not installed: {e}\")\n",
        "\n",
        "try:\n",
        "    import PIL\n",
        "    print(f\" Pillow version: {PIL.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\" Pillow not installed: {e}\")\n",
        "\n",
        "if torch is not None:\n",
        "    print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"  Note: The evaluation can run on CPU but will be VERY slow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a55f7fe8",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43554fec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create logs directory\n",
        "import os\n",
        "\n",
        "logs_dir = \"logs\"\n",
        "if not os.path.exists(logs_dir):\n",
        "    os.makedirs(logs_dir)\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc852049",
      "metadata": {},
      "source": [
        "## Run Evaluations\n",
        "Run evaluations for different models. The evaluation will:\n",
        "- Use streaming datasets (no local download needed)\n",
        "- Evaluate on different baseline accuracies (0, 20, 40)\n",
        "- Test different models (rdumb, tent, pretrained, etc.)\n",
        "**Note**: Each evaluation processes 9 runs (3 seeds × 3 transition speeds). This may take some time.\n",
        "**Important**: \n",
        "- The evaluation can run on CPU but will be VERY slow (may take days)\n",
        "- For reasonable performance, use a system with GPU and CUDA installed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "878b47bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run evaluation for RDumb model (the paper's main contribution)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Check if GPU is available to determine timeout\n",
        "try:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    if cuda_available:\n",
        "        # GPU: shorter timeout (should complete in reasonable time)\n",
        "        timeout_seconds = 7200  # 2 hours for GPU\n",
        "        device_info = f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
        "    else:\n",
        "        # CPU: much longer timeout or no timeout\n",
        "        timeout_seconds = None  # No timeout for CPU (can take many hours)\n",
        "        device_info = \"CPU\"\n",
        "except:\n",
        "    # If torch is not available, assume CPU\n",
        "    cuda_available = False\n",
        "    timeout_seconds = None\n",
        "    device_info = \"CPU\"\n",
        "\n",
        "# Ensure we're in the CCC directory\n",
        "if not os.path.exists(\"eval.py\"):\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "else:\n",
        "    # Configuration\n",
        "    mode = \"rdumb\"\n",
        "    baseline = 20  # CCC-Medium (0=Hard, 20=Medium, 40=Easy)\n",
        "    logs_path = \"logs\"\n",
        "\n",
        "    print(f\"Running evaluation for mode: {mode}, baseline: {baseline}\")\n",
        "    print(\"This will evaluate all 9 configurations (3 seeds × 3 speeds)\")\n",
        "    print(f\"Device: {device_info}\")\n",
        "    if timeout_seconds:\n",
        "        print(f\"Timeout: {timeout_seconds // 3600} hours per configuration\")\n",
        "    else:\n",
        "        print(\"Timeout: None (will run until completion)\")\n",
        "    print(\"  (CPU execution will be slower but will still work)\")\n",
        "\n",
        "    # Run evaluation for each of the 9 configurations\n",
        "    # processind 0-8 covers all combinations\n",
        "    for processind in range(9):\n",
        "        print(f\"\\nRunning evaluation {processind + 1}/9 (processind={processind})\")\n",
        "        print(\"-\"*60)\n",
        "        print(f\" This may take a while, especially on CPU. Please be patient...\")\n",
        "        \n",
        "        cmd = [\n",
        "            sys.executable, \"eval.py\",\n",
        "            \"--mode\", mode,\n",
        "            \"--baseline\", str(baseline),\n",
        "            \"--logs\", logs_path,\n",
        "            \"--processind\", str(processind),\n",
        "            \"--dset\", \"\"  # Empty since we're using streaming\n",
        "        ]\n",
        "        \n",
        "        try:\n",
        "            # Run with or without timeout\n",
        "            if timeout_seconds:\n",
        "                result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=timeout_seconds)\n",
        "            else:\n",
        "                result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "            \n",
        "            print(f\" Completed processind {processind}\")\n",
        "            if result.stdout:\n",
        "                # Only print last few lines to avoid clutter\n",
        "                lines = result.stdout.strip().split('\\n')\n",
        "                if len(lines) > 5:\n",
        "                    print(\"  ... (output truncated) ...\")\n",
        "                    for line in lines[-3:]:\n",
        "                        print(f\"  {line}\")\n",
        "                else:\n",
        "                    print(result.stdout)\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\" Timeout for processind {processind}\")\n",
        "            if timeout_seconds:\n",
        "                print(f\"  Took longer than {timeout_seconds // 3600} hours\")\n",
        "            print(\"  You can run individual configurations manually if needed.\")\n",
        "            # Don't break - continue with next configuration\n",
        "            continue\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\" Error in processind {processind}\")\n",
        "            print(f\"Error output (last 500 chars):\")\n",
        "            error_msg = e.stderr if e.stderr else e.stdout\n",
        "            if error_msg:\n",
        "                print(error_msg[-500:])\n",
        "            else:\n",
        "                print(\"No error message available\")\n",
        "            # Don't break, continue with next processind\n",
        "            continue\n",
        "\n",
        "    print(\"Evaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e2da61",
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all result files\n",
        "import os\n",
        "import glob\n",
        "\n",
        "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
        "if os.path.exists(results_dir):\n",
        "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
        "    print(f\"Found {len(result_files)} result files:\")\n",
        "    for f in sorted(result_files):\n",
        "        print(f\"  - {os.path.basename(f)}\")\n",
        "        \n",
        "    # Read and display a sample result file\n",
        "    if result_files:\n",
        "        print(\"Sample result file (first 20 lines):\")\n",
        "        with open(result_files[0], 'r') as f:\n",
        "            lines = f.readlines()[:20]\n",
        "            for i, line in enumerate(lines, 1):\n",
        "                print(f\"{i:4d}: {line.strip()}\")\n",
        "else:\n",
        "    print(f\"Directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247e640b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average accuracy from result files\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def calculate_avg_accuracy(result_file):\n",
        "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
        "    accuracies = []\n",
        "    with open(result_file, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('acc_'):\n",
        "                try:\n",
        "                    acc = float(line.split('_')[1])\n",
        "                    accuracies.append(acc)\n",
        "                except:\n",
        "                    pass\n",
        "    return np.mean(accuracies) if accuracies else None\n",
        "\n",
        "# Calculate averages for all result files\n",
        "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
        "if os.path.exists(results_dir):\n",
        "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
        "    \n",
        "    print(\"Average Accuracies:\")\n",
        "    for f in sorted(result_files):\n",
        "        avg_acc = calculate_avg_accuracy(f)\n",
        "        if avg_acc is not None:\n",
        "            filename = os.path.basename(f)\n",
        "            print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
        "    \n",
        "    # Overall average\n",
        "    all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
        "    all_accs = [a for a in all_accs if a is not None]\n",
        "    if all_accs:\n",
        "        print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
        "        print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
        "else:\n",
        "    print(f\"Directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74fbeee4",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c01b5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all result files\n",
        "# This cell searches for result files in multiple possible locations\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def find_results_directory(baseline=20):\n",
        "    \"\"\"Search for results directory in common locations.\"\"\"\n",
        "    possible_paths = [\n",
        "        os.path.join(\"logs\", f\"ccc_{baseline}\"),  # Current directory\n",
        "        os.path.join(\"CCC\", \"logs\", f\"ccc_{baseline}\"),  # CCC subdirectory\n",
        "        os.path.join(os.path.dirname(os.getcwd()), \"logs\", f\"ccc_{baseline}\"),  # Parent directory\n",
        "    ]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "    return None\n",
        "\n",
        "# Search for results\n",
        "baseline = 20\n",
        "results_dir = find_results_directory(baseline)\n",
        "\n",
        "if results_dir:\n",
        "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "    print(f\"Found {len(result_files)} result files:\")\n",
        "    for f in sorted(result_files):\n",
        "        print(f\"  - {os.path.basename(f)}\")\n",
        "        \n",
        "    # Read and display a sample result file\n",
        "    if result_files:\n",
        "        print(\"Sample result file (first 20 lines):\")\n",
        "        with open(result_files[0], 'r') as f:\n",
        "            lines = f.readlines()[:20]\n",
        "            for i, line in enumerate(lines, 1):\n",
        "                print(f\"{i:4d}: {line.strip()}\")\n",
        "else:\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "    print(\"\\nPossible reasons:\")\n",
        "    print(\"  1. Evaluation hasn't been run yet\")\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "    print(\"  3. Logs were saved to a different location\")\n",
        "    print(\"\\nTo generate results:\")\n",
        "    print(\"  → Run the evaluation cells above (they will create logs/ccc_20/)\")\n",
        "    print(f\"Directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678187f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average accuracy from result files\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def find_results_directory(baseline=20):\n",
        "    \"\"\"Search for results directory in common locations.\"\"\"\n",
        "    possible_paths = [\n",
        "        os.path.join(\"logs\", f\"ccc_{baseline}\"),  # Current directory\n",
        "        os.path.join(\"CCC\", \"logs\", f\"ccc_{baseline}\"),  # CCC subdirectory\n",
        "        os.path.join(os.path.dirname(os.getcwd()), \"logs\", f\"ccc_{baseline}\"),  # Parent directory\n",
        "    ]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "    return None\n",
        "\n",
        "def calculate_avg_accuracy(result_file):\n",
        "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
        "    accuracies = []\n",
        "    with open(result_file, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('acc_'):\n",
        "                try:\n",
        "                    acc = float(line.split('_')[1])\n",
        "                    accuracies.append(acc)\n",
        "                except:\n",
        "                    pass\n",
        "    return np.mean(accuracies) if accuracies else None\n",
        "\n",
        "# Search for results directory\n",
        "baseline = 20\n",
        "results_dir = find_results_directory(baseline)\n",
        "\n",
        "if results_dir:\n",
        "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
        "    \n",
        "    if result_files:\n",
        "        print(\"Average Accuracies:\")\n",
        "        for f in sorted(result_files):\n",
        "            avg_acc = calculate_avg_accuracy(f)\n",
        "            if avg_acc is not None:\n",
        "                filename = os.path.basename(f)\n",
        "                print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
        "        \n",
        "        # Overall average\n",
        "        all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
        "        all_accs = [a for a in all_accs if a is not None]\n",
        "        if all_accs:\n",
        "            print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
        "            print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
        "    else:\n",
        "        print(f\" No result files found in {results_dir}\")\n",
        "else:\n",
        "    print(f\"Directory: {os.getcwd()}\")\n",
        "    print(\"\\nTo generate results:\")\n",
        "    print(\"  → Run the evaluation cells above (they will create logs/ccc_20/)\")\n",
        "    print(f\"Directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab0e09d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Import required modules and configure test parameters\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "# Import torchvision with error handling for CUDA version mismatches\n",
        "# Use tv_models to avoid conflict with local 'models' module\n",
        "try:\n",
        "    import torchvision.models as tv_models\n",
        "    import torchvision.transforms as trn\n",
        "except RuntimeError as e:\n",
        "    if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
        "        print(f\"\\n CUDA version mismatch detected: {e}\")\n",
        "        \n",
        "        # Get PyTorch CUDA version\n",
        "        pytorch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
        "        print(f\"  PyTorch CUDA version: {pytorch_cuda}\")\n",
        "        \n",
        "        # Determine CUDA wheel version\n",
        "        if pytorch_cuda and pytorch_cuda.startswith(\"11.7\"):\n",
        "            cuda_wheel = \"cu117\"\n",
        "            torchvision_version = \"0.15.2\"\n",
        "        elif pytorch_cuda and pytorch_cuda.startswith(\"11.8\"):\n",
        "            cuda_wheel = \"cu118\"\n",
        "            torchvision_version = \"0.15.2\"\n",
        "        elif pytorch_cuda and pytorch_cuda.startswith(\"12.1\"):\n",
        "            cuda_wheel = \"cu121\"\n",
        "            torchvision_version = None  # Use latest\n",
        "        elif pytorch_cuda and (pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\")):\n",
        "            cuda_wheel = \"cu124\"\n",
        "            torchvision_version = None  # Use latest\n",
        "        else:\n",
        "            cuda_wheel = \"cu118\"  # Default fallback\n",
        "            torchvision_version = \"0.15.2\"\n",
        "        \n",
        "        # Uninstall and reinstall torchvision\n",
        "        print(f\"  Uninstalling torchvision...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
        "                      check=False, capture_output=True)\n",
        "        \n",
        "        print(f\"  Reinstalling torchvision with CUDA {cuda_wheel}...\")\n",
        "        if torchvision_version:\n",
        "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \n",
        "                          f\"torchvision=={torchvision_version}\",\n",
        "                          \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "        else:\n",
        "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
        "                          \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
        "        \n",
        "        try:\n",
        "            subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
        "            \n",
        "            # Try importing again\n",
        "            import torchvision.models as tv_models\n",
        "            import torchvision.transforms as trn\n",
        "        except Exception as install_error:\n",
        "            print(f\"   Failed to reinstall torchvision: {install_error}\")\n",
        "            print(f\"  Please restart the kernel and run this cell again\")\n",
        "            raise RuntimeError(\"CUDA version mismatch: Please restart kernel and run Cell 13 to fix\")\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "import webdataset as wds\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install pandas if not available (needed for results table)\n",
        "try:\n",
        "    import pandas as pd\n",
        "    print(\" Pandas already installed\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"-q\"], \n",
        "                      check=True, capture_output=True, timeout=60)\n",
        "        import pandas as pd\n",
        "    except Exception as e:\n",
        "        print(f\"   Could not install pandas: {e}\")\n",
        "        print(\"  Results table will use basic formatting instead\")\n",
        "        pd = None\n",
        "\n",
        "# Add CCC directory to path if needed\n",
        "ccc_path = os.path.join(os.getcwd(), \"CCC\")\n",
        "if os.path.exists(ccc_path) and ccc_path not in sys.path:\n",
        "    sys.path.insert(0, ccc_path)\n",
        "\n",
        "# Import registery and explicitly import rdumbpp to ensure models are registered\n",
        "from models import registery\n",
        "\n",
        "# Explicitly import rdumbpp to trigger model registration\n",
        "# This is necessary because the decorators need to run to register the models\n",
        "print(\"Importing RDumb++ models...\")\n",
        "try:\n",
        "    # Use direct import which is more reliable\n",
        "    import models.rdumbpp\n",
        "    # Also try the from import to ensure it's accessible\n",
        "    from models import rdumbpp\n",
        "    print(\" RDumb++ models imported and registered\")\n",
        "except Exception as e:\n",
        "    print(f\" Warning: Could not import rdumbpp: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# Verify registered models\n",
        "available_models = list(registery.get_options())\n",
        "print(f\"\\n Available registered models: {available_models}\")\n",
        "print(f\"  Total: {len(available_models)} models\")\n",
        "\n",
        "# Verify RDumb++ models are present\n",
        "rdumbpp_models = [m for m in available_models if m.startswith(\"rdumbpp_\")]\n",
        "if rdumbpp_models:\n",
        "    print(f\"  RDumb++ models found: {rdumbpp_models}\")\n",
        "else:\n",
        "\n",
        "# Test configuration\n",
        "BASELINE = 20  # CCC-medium\n",
        "SEED = 43\n",
        "SPEEDS = [1000, 2000, 5000]\n",
        "MAX_IMAGES = 10000  # Limit to 10K images per speed\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "print(\"MODEL COMPARISON TEST CONFIGURATION\")\n",
        "print(f\"Dataset: CCC-medium (baseline={BASELINE})\")\n",
        "print(f\"Seed: {SEED}\")\n",
        "print(f\"Speeds: {SPEEDS}\")\n",
        "print(f\"Max images per speed: {MAX_IMAGES:,}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Total images: {MAX_IMAGES * len(SPEEDS):,}\")\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nDevice: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c8b256",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function: Create data loader for a specific dataset configuration\n",
        "def get_test_loader(dset_name, max_images=MAX_IMAGES, batch_size=BATCH_SIZE):\n",
        "    \"\"\"Create a data loader limited to max_images.\"\"\"\n",
        "    url = f'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/{dset_name}/serial_{{00000..99999}}.tar'\n",
        "    \n",
        "    normalize = trn.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    preproc = trn.Compose([trn.ToTensor(), normalize])\n",
        "    \n",
        "    dataset = (\n",
        "        wds.WebDataset(url)\n",
        "        .decode(\"pil\")\n",
        "        .to_tuple(\"input.jpg\", \"output.cls\")\n",
        "        .map_tuple(preproc, lambda x: x)\n",
        "    )\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
        "    return loader\n",
        "\n",
        "# Test function: Evaluate model on limited dataset\n",
        "def test_model_limited(model, dset_name, max_images=MAX_IMAGES, is_baseline=False):\n",
        "    \"\"\"Evaluate model accuracy on limited number of images.\n",
        "    \n",
        "    Args:\n",
        "        model: The model to evaluate\n",
        "        dset_name: Dataset name\n",
        "        max_images: Maximum number of images to process\n",
        "        is_baseline: If True, use no_grad (for pretrained baseline only)\n",
        "    \"\"\"\n",
        "    # Only set eval mode for non-adaptive models\n",
        "    if is_baseline and hasattr(model, 'eval'):\n",
        "        model.eval()\n",
        "    \n",
        "    loader = get_test_loader(dset_name, max_images, BATCH_SIZE)\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    accuracies = []\n",
        "    \n",
        "    # Adaptive models need gradients, baseline doesn't\n",
        "    context = torch.no_grad() if is_baseline else torch.enable_grad()\n",
        "    \n",
        "    with context:\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            if total_images >= max_images:\n",
        "                break\n",
        "                \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # Forward pass (adaptive models handle their own adaptation)\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # Calculate accuracy (detach for accuracy calculation)\n",
        "            with torch.no_grad():\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                correct = (preds == labels).sum().item()\n",
        "                batch_size = images.size(0)\n",
        "                \n",
        "                total_correct += correct\n",
        "                total_images += batch_size\n",
        "                batch_acc = 100 * correct / batch_size\n",
        "                accuracies.append(batch_acc)\n",
        "            \n",
        "            if total_images >= max_images:\n",
        "                break\n",
        "    \n",
        "    avg_accuracy = 100 * total_correct / total_images if total_images > 0 else 0.0\n",
        "    return avg_accuracy, accuracies\n",
        "\n",
        "print(\" Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c15e9bf",
      "metadata": {},
      "source": [
        "## Running Models\n",
        "Running each model on the test dataset and collecting results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0816ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize results storage\n",
        "results = defaultdict(dict)  # results[model_name][speed] = accuracy\n",
        "model_configs = [\n",
        "    (\"Baseline\", \"pretrained\", True),   # (name, mode, is_baseline)\n",
        "    (\"RDumb\", \"rdumb\", False),\n",
        "    (\"RDumbPP_EntropyFull\", \"rdumbpp_ent_full\", False),\n",
        "    (\"RDumbPP_EntropySoft\", \"rdumbpp_ent_soft\", False),\n",
        "    (\"RDumbPP_KLFull\", \"rdumbpp_kl_full\", False),\n",
        "    (\"RDumbPP_KLSoft\", \"rdumbpp_kl_soft\", False),\n",
        "]\n",
        "\n",
        "print(\"INITIALIZING MODELS\")\n",
        "\n",
        "# Ensure torchvision.models is available (from Cell 27)\n",
        "# If tv_models is not available, import it here\n",
        "try:\n",
        "    tv_models\n",
        "except NameError:\n",
        "    print(\"  Importing torchvision.models...\")\n",
        "    import torchvision.models as tv_models\n",
        "    print(\"   torchvision.models imported\")\n",
        "\n",
        "# Verify all required models are registered\n",
        "available_models = list(registery.get_options())\n",
        "print(f\"  Currently registered: {available_models}\")\n",
        "\n",
        "# Check if RDumb++ models are registered\n",
        "required_rdumbpp_models = [\"rdumbpp_ent_full\", \"rdumbpp_ent_soft\", \"rdumbpp_kl_full\", \"rdumbpp_kl_soft\"]\n",
        "missing_models = [m for m in required_rdumbpp_models if m not in available_models]\n",
        "\n",
        "if missing_models:\n",
        "    print(f\"\\n Missing RDumb++ models: {missing_models}\")\n",
        "    print(\"  Attempting to import rdumbpp module to register models...\")\n",
        "    try:\n",
        "        # Try importing rdumbpp explicitly\n",
        "        import models.rdumbpp\n",
        "        # Also try from models import\n",
        "        from models import rdumbpp\n",
        "        print(\"   RDumb++ module imported\")\n",
        "        \n",
        "        # Check again\n",
        "        available_models = list(registery.get_options())\n",
        "        print(f\"  Updated registered models: {available_models}\")\n",
        "        missing_models = [m for m in required_rdumbpp_models if m not in available_models]\n",
        "        \n",
        "        if missing_models:\n",
        "            print(f\"\\n ERROR: Still missing models: {missing_models}\")\n",
        "            print(\"  Please check that rdumbpp.py is correctly formatted and all models are decorated with @register()\")\n",
        "            raise ValueError(f\"Required models not registered: {missing_models}\")\n",
        "        else:\n",
        "            print(\"   All RDumb++ models are now registered!\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error importing rdumbpp: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "else:\n",
        "    print(\"   All required models are registered\")\n",
        "\n",
        "# Initialize all models (each gets a fresh ResNet50 copy)\n",
        "initialized_models = {}\n",
        "model_is_baseline = {}\n",
        "\n",
        "for model_name, model_mode, is_baseline in model_configs:\n",
        "    try:\n",
        "        print(f\"\\n[{model_name}] Initializing {model_mode}...\")\n",
        "        \n",
        "        # Create a fresh ResNet50 for each model\n",
        "        # Use tv_models from Cell 27 (torchvision.models)\n",
        "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
        "        \n",
        "        if model_mode == \"pretrained\":\n",
        "            model = registery.init(model_mode, base_model)\n",
        "        elif model_mode == \"rdumb\":\n",
        "            model = registery.init(model_mode, base_model)\n",
        "        elif model_mode.startswith(\"rdumbpp_\"):\n",
        "            # RDumb++ models need additional parameters\n",
        "            model = registery.init(\n",
        "                model_mode, base_model,\n",
        "                drift_k=3.0,\n",
        "                warmup_steps=50,\n",
        "                cooldown_steps=200,\n",
        "                soft_lambda=0.5,\n",
        "                entropy_ema_alpha=0.99,\n",
        "                kl_ema_alpha=0.99\n",
        "            )\n",
        "        else:\n",
        "            model = registery.init(model_mode, base_model)\n",
        "        \n",
        "        initialized_models[model_name] = model\n",
        "        model_is_baseline[model_name] = is_baseline\n",
        "        print(f\"   {model_name} initialized successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error initializing {model_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(f\"\\n Initialized {len(initialized_models)}/{len(model_configs)} models\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc00e355",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run evaluation for each model and speed\n",
        "print(\"RUNNING EVALUATIONS\")\n",
        "\n",
        "for model_name, model in initialized_models.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"MODEL: {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    is_baseline = model_is_baseline.get(model_name, False)\n",
        "    \n",
        "    for speed in SPEEDS:\n",
        "        dset_name = f\"baseline_{BASELINE}_transition+speed_{speed}_seed_{SEED}\"\n",
        "        print(f\"\\n  Testing on speed={speed} (dataset: {dset_name})...\")\n",
        "        \n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=is_baseline)\n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            results[model_name][speed] = {\n",
        "                'accuracy': avg_acc,\n",
        "                'time': elapsed,\n",
        "                'batches': len(batch_accs)\n",
        "            }\n",
        "            \n",
        "            print(f\"   Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s | Batches: {len(batch_accs)}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   Error: {e}\")\n",
        "            results[model_name][speed] = {'accuracy': None, 'error': str(e)}\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "print(\"EVALUATION COMPLETE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac14dd2",
      "metadata": {},
      "source": [
        "## Results Table\n",
        "Summary of all model performances across different speeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b6c88d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results in a formatted table\n",
        "try:\n",
        "    import pandas as pd\n",
        "    use_pandas = True\n",
        "except ImportError:\n",
        "    print(\" Pandas not available. Using basic table formatting...\")\n",
        "    use_pandas = False\n",
        "    # Try to install pandas\n",
        "    try:\n",
        "        import subprocess\n",
        "        import sys\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"-q\"], \n",
        "                      check=True, capture_output=True, timeout=60)\n",
        "        import pandas as pd\n",
        "        use_pandas = True\n",
        "    except:\n",
        "        print(\"  (Continuing without pandas)\")\n",
        "\n",
        "print(\"RESULTS SUMMARY\")\n",
        "\n",
        "# Prepare data for table\n",
        "table_data = []\n",
        "for model_name in [m[0] for m in model_configs]:\n",
        "    row = {'Model': model_name}\n",
        "    speeds_acc = []\n",
        "    \n",
        "    for speed in SPEEDS:\n",
        "        if model_name in results and speed in results[model_name]:\n",
        "            acc = results[model_name][speed].get('accuracy')\n",
        "            if acc is not None:\n",
        "                row[f'Speed {speed}'] = f\"{acc:.4f}%\"\n",
        "                speeds_acc.append(acc)\n",
        "            else:\n",
        "                row[f'Speed {speed}'] = \"Error\"\n",
        "        else:\n",
        "            row[f'Speed {speed}'] = \"N/A\"\n",
        "    \n",
        "    # Calculate average across speeds\n",
        "    if speeds_acc:\n",
        "        row['Average'] = f\"{np.mean(speeds_acc):.4f}%\"\n",
        "    else:\n",
        "        row['Average'] = \"N/A\"\n",
        "    \n",
        "    table_data.append(row)\n",
        "\n",
        "# Display table (with or without pandas)\n",
        "if use_pandas:\n",
        "    # Create and display DataFrame\n",
        "    df = pd.DataFrame(table_data)\n",
        "    df = df[['Model'] + [f'Speed {s}' for s in SPEEDS] + ['Average']]\n",
        "    print(\"\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "else:\n",
        "    # Basic table formatting without pandas\n",
        "    print(\"\\n\")\n",
        "    # Header\n",
        "    header = f\"{'Model':<30} \" + \" \".join([f\"{f'Speed {s}':>12}\" for s in SPEEDS]) + f\" {'Average':>12}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    # Rows\n",
        "    for row in table_data:\n",
        "        model = row['Model']\n",
        "        speed_cols = \" \".join([f\"{row.get(f'Speed {s}', 'N/A'):>12}\" for s in SPEEDS])\n",
        "        avg = row.get('Average', 'N/A')\n",
        "        print(f\"{model:<30} {speed_cols} {avg:>12}\")\n",
        "\n",
        "\n",
        "# Also create a summary\n",
        "print(\"\\nSUMMARY STATISTICS:\")\n",
        "print(\"-\"*70)\n",
        "for model_name in [m[0] for m in model_configs]:\n",
        "    if model_name in results:\n",
        "        all_accs = [results[model_name][s].get('accuracy') \n",
        "                   for s in SPEEDS \n",
        "                   if results[model_name][s].get('accuracy') is not None]\n",
        "        if all_accs:\n",
        "            print(f\"{model_name:30s} | Avg: {np.mean(all_accs):6.4f}% | \"\n",
        "                  f\"Min: {np.min(all_accs):6.4f}% | Max: {np.max(all_accs):6.4f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936f7e0c",
      "metadata": {},
      "source": [
        "# Ablation Study: RDumb++ Hyperparameters\n",
        "This section performs an ablation study on RDumb++ hyperparameters to understand their impact on performance:\n",
        "1. **Drift Threshold (drift_k)**: Controls sensitivity of drift detection (default: 3.0)\n",
        "   - Higher values = less sensitive (fewer resets)\n",
        "   - Lower values = more sensitive (more frequent resets)\n",
        "2. **Divergence Threshold (d_margin)**: Cosine similarity threshold for filtering redundant samples (default: 0.05)\n",
        "   - Higher values = more samples included\n",
        "   - Lower values = stricter filtering\n",
        "3. **Lambda Threshold (soft_lambda)**: Interpolation weight for soft reset (default: 0.5)\n",
        "   - Higher values = closer to initial state\n",
        "   - Lower values = closer to current state\n",
        "**Study Design:**\n",
        "- Test each parameter independently while keeping others at default\n",
        "- Use RDumb++_EntropySoft model (best performing variant)\n",
        "- Evaluate on CCC-medium (baseline=20, seed=43, speed=1000)\n",
        "- Limited to 10K images for faster iteration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd6a5b9",
      "metadata": {},
      "source": [
        "## Ablation 1: Drift Threshold (drift_k)\n",
        "Testing different drift detection sensitivity values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1336c4aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ablation Study 1: Drift Threshold (drift_k)\n",
        "print(\"ABLATION 1: DRIFT THRESHOLD (drift_k)\")\n",
        "print(\"Testing sensitivity of drift detection...\")\n",
        "\n",
        "ablation1_results = {}\n",
        "test_speed = 1000  # Use single speed for faster iteration\n",
        "dset_name = f\"baseline_{BASELINE}_transition+speed_{test_speed}_seed_{SEED}\"\n",
        "\n",
        "for drift_k in DRIFT_K_VALUES:\n",
        "    print(f\"\\n[Testing drift_k={drift_k}]\")\n",
        "    \n",
        "    try:\n",
        "        # Create fresh ResNet50\n",
        "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
        "        \n",
        "        # Initialize RDumb++ with specific drift_k\n",
        "        model = registery.init(\n",
        "            \"rdumbpp_ent_soft\", base_model,\n",
        "            drift_k=drift_k,\n",
        "            warmup_steps=50,\n",
        "            cooldown_steps=200,\n",
        "            soft_lambda=0.5,  # Default\n",
        "            entropy_ema_alpha=0.99,\n",
        "            kl_ema_alpha=0.99\n",
        "        )\n",
        "        \n",
        "        # Evaluate\n",
        "        start_time = time.time()\n",
        "        avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=False)\n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        ablation1_results[drift_k] = {\n",
        "            'accuracy': avg_acc,\n",
        "            'time': elapsed,\n",
        "            'batches': len(batch_accs)\n",
        "        }\n",
        "        \n",
        "        print(f\"   Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "        ablation1_results[drift_k] = {'accuracy': None, 'error': str(e)}\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(\"ABLATION 1 COMPLETE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "612ad886",
      "metadata": {},
      "source": [
        "## Ablation 2: Divergence Threshold (d_margin)\n",
        "Testing different cosine similarity thresholds for filtering redundant samples.\n",
        "**Note:** `d_margin` is a hardcoded parameter in RDumb++. We'll need to modify the model temporarily or create a wrapper to test different values. For this study, we'll note the default value (0.05) and focus on other tunable parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe3191d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ablation Study 2: Divergence Threshold (d_margin)\n",
        "# We'll document the default and note that it's not easily tunable without code modification.\n",
        "\n",
        "print(\"ABLATION 2: DIVERGENCE THRESHOLD (d_margin)\")\n",
        "print(\" NOTE: d_margin is hardcoded to 0.05 in RDumb++ implementation\")\n",
        "print(\"To test different values, the model code would need modification.\")\n",
        "print(f\"\\nDefault d_margin value: 0.05\")\n",
        "print(\"This parameter controls cosine similarity threshold for filtering redundant samples.\")\n",
        "print(\"\\nFor this ablation, we'll use the default value and focus on tunable parameters.\")\n",
        "\n",
        "# Store note about d_margin\n",
        "ablation2_results = {\n",
        "    'note': 'd_margin is hardcoded to 0.05 in RDumb++',\n",
        "    'default_value': 0.05,\n",
        "    'description': 'Cosine similarity threshold for redundant sample filtering'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22d7d88",
      "metadata": {},
      "source": [
        "## Ablation 3: Lambda Threshold (soft_lambda)\n",
        "Testing different interpolation weights for soft reset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aaf5701",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ablation Study 3: Lambda Threshold (soft_lambda)\n",
        "print(\"ABLATION 3: LAMBDA THRESHOLD (soft_lambda)\")\n",
        "print(\"Testing soft reset interpolation weights...\")\n",
        "\n",
        "ablation3_results = {}\n",
        "test_speed = 1000\n",
        "dset_name = f\"baseline_{BASELINE}_transition+speed_{test_speed}_seed_{SEED}\"\n",
        "\n",
        "for soft_lambda in SOFT_LAMBDA_VALUES:\n",
        "    print(f\"\\n[Testing soft_lambda={soft_lambda}]\")\n",
        "    \n",
        "    try:\n",
        "        # Create fresh ResNet50\n",
        "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
        "        \n",
        "        # Initialize RDumb++ with specific soft_lambda\n",
        "        model = registery.init(\n",
        "            \"rdumbpp_ent_soft\", base_model,\n",
        "            drift_k=3.0,  # Default\n",
        "            warmup_steps=50,\n",
        "            cooldown_steps=200,\n",
        "            soft_lambda=soft_lambda,\n",
        "            entropy_ema_alpha=0.99,\n",
        "            kl_ema_alpha=0.99\n",
        "        )\n",
        "        \n",
        "        # Evaluate\n",
        "        start_time = time.time()\n",
        "        avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=False)\n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        ablation3_results[soft_lambda] = {\n",
        "            'accuracy': avg_acc,\n",
        "            'time': elapsed,\n",
        "            'batches': len(batch_accs)\n",
        "        }\n",
        "        \n",
        "        print(f\"   Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "        ablation3_results[soft_lambda] = {'accuracy': None, 'error': str(e)}\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(\"ABLATION 3 COMPLETE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa12a15",
      "metadata": {},
      "source": [
        "## Ablation Study Results Summary\n",
        "Comparing the effects of different hyperparameter values on model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97461f02",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Ablation Study Results\n",
        "try:\n",
        "    import pandas as pd\n",
        "    use_pandas = True\n",
        "except ImportError:\n",
        "    use_pandas = False\n",
        "\n",
        "print(\"ABLATION STUDY RESULTS SUMMARY\")\n",
        "\n",
        "# Results for Drift Threshold (drift_k)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"1. DRIFT THRESHOLD (drift_k) ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "if ablation1_results:\n",
        "    drift_data = []\n",
        "    for drift_k in sorted(DRIFT_K_VALUES):\n",
        "        if drift_k in ablation1_results:\n",
        "            acc = ablation1_results[drift_k].get('accuracy')\n",
        "            if acc is not None:\n",
        "                drift_data.append({\n",
        "                    'drift_k': drift_k,\n",
        "                    'Accuracy (%)': f\"{acc:.4f}\",\n",
        "                    'Time (s)': f\"{ablation1_results[drift_k].get('time', 0):.2f}\"\n",
        "                })\n",
        "    \n",
        "    if use_pandas and drift_data:\n",
        "        df_drift = pd.DataFrame(drift_data)\n",
        "        print(\"\\n\")\n",
        "        print(df_drift.to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\nDrift Threshold Results:\")\n",
        "        print(f\"{'drift_k':<10} {'Accuracy (%)':<15} {'Time (s)':<10}\")\n",
        "        print(\"-\" * 35)\n",
        "        for row in drift_data:\n",
        "            print(f\"{row['drift_k']:<10} {row['Accuracy (%)']:<15} {row['Time (s)']:<10}\")\n",
        "    \n",
        "    # Find best\n",
        "    valid_results = [(k, v['accuracy']) for k, v in ablation1_results.items() \n",
        "                     if v.get('accuracy') is not None]\n",
        "    if valid_results:\n",
        "        best_drift_k, best_acc = max(valid_results, key=lambda x: x[1])\n",
        "        print(f\"\\n Best drift_k: {best_drift_k} (Accuracy: {best_acc:.4f}%)\")\n",
        "else:\n",
        "    print(\"No results available\")\n",
        "\n",
        "# Results for Lambda Threshold (soft_lambda)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"2. LAMBDA THRESHOLD (soft_lambda) ANALYSIS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "if ablation3_results:\n",
        "    lambda_data = []\n",
        "    for soft_lambda in sorted(SOFT_LAMBDA_VALUES):\n",
        "        if soft_lambda in ablation3_results:\n",
        "            acc = ablation3_results[soft_lambda].get('accuracy')\n",
        "            if acc is not None:\n",
        "                lambda_data.append({\n",
        "                    'soft_lambda': soft_lambda,\n",
        "                    'Accuracy (%)': f\"{acc:.4f}\",\n",
        "                    'Time (s)': f\"{ablation3_results[soft_lambda].get('time', 0):.2f}\"\n",
        "                })\n",
        "    \n",
        "    if use_pandas and lambda_data:\n",
        "        df_lambda = pd.DataFrame(lambda_data)\n",
        "        print(\"\\n\")\n",
        "        print(df_lambda.to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\nLambda Threshold Results:\")\n",
        "        print(f\"{'soft_lambda':<12} {'Accuracy (%)':<15} {'Time (s)':<10}\")\n",
        "        print(\"-\" * 37)\n",
        "        for row in lambda_data:\n",
        "            print(f\"{row['soft_lambda']:<12} {row['Accuracy (%)']:<15} {row['Time (s)']:<10}\")\n",
        "    \n",
        "    # Find best\n",
        "    valid_results = [(k, v['accuracy']) for k, v in ablation3_results.items() \n",
        "                     if v.get('accuracy') is not None]\n",
        "    if valid_results:\n",
        "        best_lambda, best_acc = max(valid_results, key=lambda x: x[1])\n",
        "        print(f\"\\n Best soft_lambda: {best_lambda} (Accuracy: {best_acc:.4f}%)\")\n",
        "else:\n",
        "    print(\"No results available\")\n",
        "\n",
        "# Note about d_margin\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"3. DIVERGENCE THRESHOLD (d_margin) NOTE\")\n",
        "print(\"-\"*70)\n",
        "print(f\"Default value: {ablation2_results.get('default_value', 0.05)}\")\n",
        "print(f\"Description: {ablation2_results.get('description', 'N/A')}\")\n",
        "print(\" This parameter is hardcoded in RDumb++ and requires code modification to test different values.\")\n",
        "\n",
        "print(\"ABLATION STUDY COMPLETE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e53a16",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparative Analysis: Best vs Default Parameters\n",
        "print(\"COMPARATIVE ANALYSIS: BEST vs DEFAULT PARAMETERS\")\n",
        "\n",
        "# Default parameters\n",
        "default_drift_k = 3.0\n",
        "default_soft_lambda = 0.5\n",
        "\n",
        "# Find best parameters\n",
        "best_drift_k = None\n",
        "best_soft_lambda = None\n",
        "\n",
        "if ablation1_results:\n",
        "    valid = [(k, v['accuracy']) for k, v in ablation1_results.items() \n",
        "             if v.get('accuracy') is not None]\n",
        "    if valid:\n",
        "        best_drift_k, best_drift_acc = max(valid, key=lambda x: x[1])\n",
        "        default_drift_acc = ablation1_results.get(default_drift_k, {}).get('accuracy')\n",
        "        \n",
        "        print(f\"\\nDrift Threshold (drift_k):\")\n",
        "        print(f\"  Default: {default_drift_k} → Accuracy: {default_drift_acc:.4f}%\" if default_drift_acc else f\"  Default: {default_drift_k} → Not tested\")\n",
        "        print(f\"  Best:    {best_drift_k} → Accuracy: {best_drift_acc:.4f}%\")\n",
        "        if default_drift_acc:\n",
        "            improvement = best_drift_acc - default_drift_acc\n",
        "            print(f\"  Improvement: {improvement:+.4f}% ({improvement/default_drift_acc*100:+.2f}%)\")\n",
        "\n",
        "if ablation3_results:\n",
        "    valid = [(k, v['accuracy']) for k, v in ablation3_results.items() \n",
        "             if v.get('accuracy') is not None]\n",
        "    if valid:\n",
        "        best_soft_lambda, best_lambda_acc = max(valid, key=lambda x: x[1])\n",
        "        default_lambda_acc = ablation3_results.get(default_soft_lambda, {}).get('accuracy')\n",
        "        \n",
        "        print(f\"\\nLambda Threshold (soft_lambda):\")\n",
        "        print(f\"  Default: {default_soft_lambda} → Accuracy: {default_lambda_acc:.4f}%\" if default_lambda_acc else f\"  Default: {default_soft_lambda} → Not tested\")\n",
        "        print(f\"  Best:    {best_soft_lambda} → Accuracy: {best_lambda_acc:.4f}%\")\n",
        "        if default_lambda_acc:\n",
        "            improvement = best_lambda_acc - default_lambda_acc\n",
        "            print(f\"  Improvement: {improvement:+.4f}% ({improvement/default_lambda_acc*100:+.2f}%)\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"RECOMMENDED PARAMETERS:\")\n",
        "print(\"-\"*70)\n",
        "if best_drift_k:\n",
        "    print(f\"  drift_k: {best_drift_k} (default: {default_drift_k})\")\n",
        "if best_soft_lambda:\n",
        "    print(f\"  soft_lambda: {best_soft_lambda} (default: {default_soft_lambda})\")\n",
        "print(f\"  d_margin: 0.05 (hardcoded, not tunable)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
