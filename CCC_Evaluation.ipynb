{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1819e31",
   "metadata": {},
   "source": [
    "# CCC (Continuously Changing Corruptions) Evaluation Notebook\n",
    "\n",
    "This notebook sets up the CCC repository, installs dependencies, and runs evaluations for test-time adaptation models.\n",
    "\n",
    "## Python Version Requirements\n",
    "\n",
    "**Recommended: Python 3.9 or 3.10**\n",
    "\n",
    "The code uses:\n",
    "- f-strings (Python 3.6+)\n",
    "- Type hints (Python 3.5+)\n",
    "- PyTorch 1.9+ (supports Python 3.6-3.10)\n",
    "\n",
    "**Best choice: Python 3.9 or 3.10** for optimal compatibility with PyTorch and all dependencies.\n",
    "\n",
    "## CUDA Version Compatibility\n",
    "\n",
    "**Important:** This notebook automatically handles CUDA version compatibility!\n",
    "\n",
    "- **Different GPUs:** The notebook works with any NVIDIA GPU (RTX 4000, RTX 5090, A100, etc.)\n",
    "- **CUDA Version Mismatch:** The notebook automatically detects and fixes mismatches between PyTorch and torchvision CUDA versions\n",
    "- **Automatic Fixes:** Cells 5, 9, 13, and 20 all automatically detect your PyTorch CUDA version and install matching torchvision\n",
    "- **No Manual Intervention:** You don't need to manually specify CUDA versions - the notebook handles it\n",
    "\n",
    "**How it works:**\n",
    "1. Detects your existing PyTorch CUDA version (11.7, 11.8, 12.1, etc.)\n",
    "2. Automatically installs torchvision with the matching CUDA version\n",
    "3. If a mismatch is detected, it automatically fixes it\n",
    "\n",
    "**Note:** If you switch to a different system/GPU with a different PyTorch installation, the notebook will automatically adapt and fix any version mismatches.\n",
    "\n",
    "## Overview\n",
    "- Check Python version\n",
    "- Clone the CCC repository\n",
    "- Install required dependencies (with compatible versions)\n",
    "- Run evaluations for different models and configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0151b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.18\n",
      "Python version info: 3.10.18 (main, Jun  4 2025, 08:56:00) [GCC 13.3.0]\n",
      "âœ“ Python version is compatible (3.9+ recommended)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "python_version = sys.version_info\n",
    "print(f\"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "print(f\"Python version info: {sys.version}\")\n",
    "\n",
    "# Check if Python version is compatible\n",
    "if python_version.major == 3 and python_version.minor >= 8:\n",
    "    if python_version.minor >= 9:\n",
    "        print(\"âœ“ Python version is compatible (3.9+ recommended)\")\n",
    "    else:\n",
    "        print(\"âš  Python 3.8 detected. Python 3.9 or 3.10 is recommended for best compatibility.\")\n",
    "else:\n",
    "    print(\"âœ— Python version may not be compatible. Please use Python 3.8 or higher (3.9-3.10 recommended).\")\n",
    "    print(\"  The code requires Python 3.6+ but PyTorch works best with Python 3.8-3.10.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658c523",
   "metadata": {},
   "source": [
    "## Clone Repository\n",
    "\n",
    "Clone the CCC repository if not already present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d2c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists at /workspace/CS532L_Project/CCC\n",
      "Current directory: /workspace/CS532L_Project/CCC\n",
      "Repository path: /workspace/CS532L_Project/CCC\n"
     ]
    }
   ],
   "source": [
    "# Check if repository is already cloned, if not clone it\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Determine the base directory (where the notebook is located)\n",
    "base_dir = os.getcwd()\n",
    "# If we're already in CCC directory, go up one level\n",
    "if os.path.basename(base_dir) == \"CCC\":\n",
    "    base_dir = os.path.dirname(base_dir)\n",
    "\n",
    "repo_name = \"CCC\"\n",
    "repo_path = os.path.join(base_dir, repo_name)\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"Cloning CCC repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/oripress/CCC.git\"], cwd=base_dir, check=True)\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(f\"Repository already exists at {repo_path}\")\n",
    "\n",
    "# Change to the CCC directory for running evaluations\n",
    "os.chdir(repo_path)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Repository path: {repo_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521c81d",
   "metadata": {},
   "source": [
    "## ðŸ”§ GPU Setup and Installation\n",
    "\n",
    "**âš  IMPORTANT: This notebook must run on RunPod, not your local Mac!**\n",
    "\n",
    "**You're currently running on:** Your local Mac (no GPU support)  \n",
    "**You need to run on:** RunPod server (has GPU)\n",
    "\n",
    "### Option 1: Run Jupyter on RunPod (RECOMMENDED)\n",
    "\n",
    "1. **SSH into RunPod:**\n",
    "   ```bash\n",
    "   ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\n",
    "   ```\n",
    "\n",
    "2. **On RunPod, install Jupyter:**\n",
    "   ```bash\n",
    "   pip install jupyter notebook\n",
    "   ```\n",
    "\n",
    "3. **Start Jupyter on RunPod:**\n",
    "   ```bash\n",
    "   jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root\n",
    "   ```\n",
    "\n",
    "4. **Access from your Mac:**\n",
    "   - Copy the URL with token from RunPod terminal\n",
    "   - Or use port forwarding: `ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io`\n",
    "   - Then open `http://localhost:8888` in your browser\n",
    "\n",
    "### Option 2: Use RunPod's Built-in Jupyter\n",
    "\n",
    "If RunPod has Jupyter pre-installed, access it through RunPod's web interface.\n",
    "\n",
    "### âœ… Automatic CUDA Version Handling\n",
    "\n",
    "**Good news:** This notebook automatically handles CUDA version compatibility!\n",
    "\n",
    "- **Works with any GPU:** RTX 4000, RTX 5090, A100, V100, etc.\n",
    "- **Automatic detection:** Detects your PyTorch CUDA version automatically\n",
    "- **Auto-fix:** Automatically installs matching torchvision version\n",
    "- **No manual config:** You don't need to specify CUDA versions\n",
    "\n",
    "**If you switch GPUs or systems:** Just run the cells from the start - the notebook will automatically detect and fix any CUDA version mismatches.\n",
    "\n",
    "**Then run the cell below on RunPod to setup GPU.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a937cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU SETUP AND VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "[Step 0] System Check...\n",
      "  System: Linux\n",
      "  Hostname: 97ec1cda9a83\n",
      "  Python: /bin/python3.10\n",
      "\n",
      "[Step 1] Checking GPU Hardware...\n",
      "  âœ“ GPU detected: NVIDIA RTX 4000 Ada Generation, 550.127.05\n",
      "\n",
      "[Step 2] Python Environment:\n",
      "  Python: /bin/python3.10\n",
      "  Version: 3.10.18\n",
      "\n",
      "[Step 3] Checking Current PyTorch Installation...\n",
      "  âœ“ PyTorch version: 2.0.1+cu117\n",
      "  âœ“ PyTorch location: /usr/local/lib/python3.10/dist-packages/torch/__init__.py\n",
      "  âœ“ Torchvision version: 0.15.2+cu117\n",
      "  âœ“ CUDA version: 11.7\n",
      "  âœ“ GPU: NVIDIA RTX 4000 Ada Generation\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Test if there's a version mismatch by trying to use torchvision\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# This will fail if versions don't match\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     test_img \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸŽ‰ SUCCESS! GPU is already working!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SINGLE CELL: GPU Setup and Verification\n",
    "# This cell handles everything needed to connect to GPU\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU SETUP AND VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 0: Check if running on correct system\n",
    "print(\"\\n[Step 0] System Check...\")\n",
    "system = platform.system()\n",
    "hostname = platform.node()\n",
    "python_path = sys.executable\n",
    "\n",
    "print(f\"  System: {system}\")\n",
    "print(f\"  Hostname: {hostname}\")\n",
    "print(f\"  Python: {python_path}\")\n",
    "\n",
    "# Check if running on Mac (local) vs Linux (RunPod)\n",
    "if system == \"Darwin\" or \"miniconda3\" in python_path or \"Users\" in python_path:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âš  WARNING: You're running on your LOCAL MAC!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nMacs don't support CUDA/GPU. You need to run this on RunPod!\")\n",
    "    print(\"\\nTo fix this:\")\n",
    "    print(\"  1. SSH into RunPod:\")\n",
    "    print(\"     ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
    "    print(\"\\n  2. On RunPod, start Jupyter:\")\n",
    "    print(\"     pip install jupyter\")\n",
    "    print(\"     jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\")\n",
    "    print(\"\\n  3. Access from your Mac using port forwarding:\")\n",
    "    print(\"     ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
    "    print(\"     Then open http://localhost:8888 in browser\")\n",
    "    print(\"\\n  4. Upload this notebook to RunPod and run it there\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"Cannot install CUDA PyTorch on Mac. Please run on RunPod.\")\n",
    "\n",
    "# Step 1: Check GPU Hardware\n",
    "print(\"\\n[Step 1] Checking GPU Hardware...\")\n",
    "try:\n",
    "    result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,driver_version\", \"--format=csv,noheader\"], \n",
    "                           capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        gpu_info = result.stdout.strip().split('\\n')[0]\n",
    "        print(f\"  âœ“ GPU detected: {gpu_info}\")\n",
    "        gpu_available = True\n",
    "    else:\n",
    "        print(\"  âš  nvidia-smi not available\")\n",
    "        gpu_available = False\n",
    "except Exception as e:\n",
    "    print(f\"  âš  Could not check GPU: {e}\")\n",
    "    gpu_available = False\n",
    "\n",
    "# Step 2: Check Python Environment\n",
    "print(f\"\\n[Step 2] Python Environment:\")\n",
    "print(f\"  Python: {sys.executable}\")\n",
    "print(f\"  Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Step 3: Check Current PyTorch Installation\n",
    "print(f\"\\n[Step 3] Checking Current PyTorch Installation...\")\n",
    "need_install = False  # Initialize variable\n",
    "torch_installed = False\n",
    "cuda_available = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch_installed = True\n",
    "    print(f\"  âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  âœ“ PyTorch location: {torch.__file__}\")\n",
    "    \n",
    "    # Check for CUDA version mismatch\n",
    "    try:\n",
    "        import torchvision\n",
    "        print(f\"  âœ“ Torchvision version: {torchvision.__version__}\")\n",
    "        \n",
    "        # Try to check CUDA versions\n",
    "        try:\n",
    "            torch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
    "            # This might raise an error if versions don't match\n",
    "            cuda_available = torch.cuda.is_available()\n",
    "            \n",
    "            if cuda_available:\n",
    "                print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "                print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                \n",
    "                # Test if there's a version mismatch by trying to use torchvision\n",
    "                try:\n",
    "                    # This will fail if versions don't match\n",
    "                    test_img = torchvision.transforms.ToTensor()(torch.zeros(3, 224, 224))\n",
    "                    print(\"\\n\" + \"=\"*70)\n",
    "                    print(\"ðŸŽ‰ SUCCESS! GPU is already working!\")\n",
    "                    print(\"=\"*70)\n",
    "                    print(\"\\nYou can proceed with evaluation. No installation needed.\")\n",
    "                    need_install = False\n",
    "                except RuntimeError as e:\n",
    "                    if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
    "                        print(\"  âš  CUDA version mismatch detected!\")\n",
    "                        print(f\"  Error: {e}\")\n",
    "                        print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
    "                        need_install = True\n",
    "                    else:\n",
    "                        raise\n",
    "            else:\n",
    "                print(\"  âš  CUDA not available - need to install CUDA PyTorch\")\n",
    "                need_install = True\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
    "                print(\"  âš  CUDA version mismatch detected!\")\n",
    "                print(f\"  Error: {e}\")\n",
    "                print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
    "                need_install = True\n",
    "            else:\n",
    "                print(f\"  âš  Error checking CUDA: {e}\")\n",
    "                need_install = True\n",
    "    except ImportError:\n",
    "        print(\"  âš  Torchvision not installed\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"  PyTorch has CUDA but torchvision missing - will install\")\n",
    "            need_install = True\n",
    "        else:\n",
    "            need_install = True\n",
    "            \n",
    "except ImportError:\n",
    "    print(\"  âš  PyTorch not installed\")\n",
    "    need_install = True\n",
    "    torch_installed = False\n",
    "\n",
    "# Step 4: Install CUDA PyTorch if needed\n",
    "if need_install:\n",
    "    print(f\"\\n[Step 4] Installing CUDA-enabled PyTorch...\")\n",
    "    print(\"  This will install PyTorch 2.0.1 with CUDA 11.8 support\")\n",
    "    print(\"  (CUDA 11.8 is compatible with CUDA 12.x systems)\")\n",
    "    \n",
    "    # Uninstall existing PyTorch first\n",
    "    if torch_installed:\n",
    "        print(\"  Uninstalling existing PyTorch...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                      check=False, capture_output=True)\n",
    "    \n",
    "    # Install NumPy first (required)\n",
    "    print(\"  Installing NumPy < 2.0...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"], \n",
    "                      check=True, capture_output=True, timeout=60)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check if we just need to fix torchvision version mismatch\n",
    "    if torch_installed and cuda_available:\n",
    "        print(\"  Fixing CUDA version mismatch...\")\n",
    "        print(\"  Reinstalling torchvision to match PyTorch CUDA version...\")\n",
    "        try:\n",
    "            # Uninstall torchvision first\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                          check=False, capture_output=True)\n",
    "            # Reinstall torchvision matching PyTorch's CUDA version\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
    "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=300\n",
    "            )\n",
    "            print(\"    âœ“ Torchvision reinstalled successfully!\")\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f\"    âœ— Failed to fix version mismatch: {str(e)[:100]}\")\n",
    "            print(\"    Will try full reinstall...\")\n",
    "            success = False\n",
    "    else:\n",
    "        success = False\n",
    "    \n",
    "    # Install CUDA PyTorch - try multiple methods\n",
    "    if not success:\n",
    "        print(\"  Installing PyTorch with CUDA 11.8...\")\n",
    "        \n",
    "        # Method 1: Using --index-url (recommended)\n",
    "        try:\n",
    "            print(\"    Trying method 1: --index-url...\")\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
    "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=600\n",
    "            )\n",
    "            print(\"    âœ“ Installation successful!\")\n",
    "            success = True\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"    âœ— Timeout - trying alternative method...\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "            print(\"    Trying alternative method...\")\n",
    "        \n",
    "        # Method 2: Using extra-index-url\n",
    "        if not success:\n",
    "            try:\n",
    "                print(\"    Trying method 2: --extra-index-url...\")\n",
    "                result = subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
    "                     \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=600\n",
    "                )\n",
    "                print(\"    âœ“ Installation successful!\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "        \n",
    "        # Method 3: Install separately to ensure matching versions\n",
    "        if not success:\n",
    "            print(\"    Trying method 3: Separate installation...\")\n",
    "            try:\n",
    "                # Install PyTorch first\n",
    "                subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\",\n",
    "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    timeout=300\n",
    "                )\n",
    "                # Then install matching torchvision\n",
    "                subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
    "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    timeout=300\n",
    "                )\n",
    "                print(\"    âœ“ Installation successful!\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âš  INSTALLATION FAILED\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nPlease install manually in terminal:\")\n",
    "        print(f\"  {sys.executable} -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        print(\"\\nThen restart kernel and run this cell again.\")\n",
    "        raise RuntimeError(\"CUDA PyTorch installation failed\")\n",
    "    \n",
    "    print(\"\\n  âœ“ CUDA PyTorch installed successfully!\")\n",
    "    print(\"  âš  IMPORTANT: Restarting kernel to load new PyTorch...\")\n",
    "    print(\"  (You may need to manually restart: Kernel â†’ Restart)\")\n",
    "\n",
    "# Step 5: Final Verification\n",
    "print(f\"\\n[Step 5] Final GPU Verification...\")\n",
    "print(\"  (If you just installed, restart kernel first!)\")\n",
    "\n",
    "try:\n",
    "    # Force reload if just installed\n",
    "    if need_install:\n",
    "        import importlib\n",
    "        if 'torch' in sys.modules:\n",
    "            importlib.reload(sys.modules['torch'])\n",
    "    \n",
    "    import torch\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    if cuda_available:\n",
    "        print(f\"  âœ“ CUDA available: True\")\n",
    "        print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  âœ“ Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        # Test GPU with actual computation\n",
    "        try:\n",
    "            print(\"  Testing GPU computation...\")\n",
    "            test_tensor = torch.randn(100, 100).cuda()\n",
    "            result = test_tensor @ test_tensor\n",
    "            print(\"  âœ“ GPU computation test: SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— GPU computation test failed: {e}\")\n",
    "            raise\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸŽ‰ SUCCESS! GPU IS FULLY CONNECTED AND WORKING!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nâœ“ GPU hardware detected\")\n",
    "        print(\"âœ“ CUDA PyTorch installed\")\n",
    "        print(\"âœ“ GPU computation verified\")\n",
    "        print(\"\\nYou can now proceed with evaluation cells.\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"  âœ— CUDA still not available\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âš  GPU NOT DETECTED\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(\"  1. Kernel not restarted after installation\")\n",
    "        print(\"     â†’ Go to: Kernel â†’ Restart & Clear Output\")\n",
    "        print(\"     â†’ Then run this cell again\")\n",
    "        print(\"\\n  2. Python environment mismatch\")\n",
    "        print(f\"     â†’ Terminal Python: Check with 'which python3'\")\n",
    "        print(f\"     â†’ Notebook Python: {sys.executable}\")\n",
    "        print(\"     â†’ They should match!\")\n",
    "        print(\"\\n  3. CUDA libraries not found\")\n",
    "        print(\"     â†’ Check: ls /usr/local/cuda*/lib64\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error during verification: {e}\")\n",
    "    print(\"\\nPlease restart kernel and run this cell again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d2d12",
   "metadata": {},
   "source": [
    "## âš  IMPORTANT: GPU Detection\n",
    "\n",
    "**If you installed CUDA PyTorch in the terminal, you MUST restart the Jupyter kernel!**\n",
    "\n",
    "The kernel needs to be restarted to load the new CUDA-enabled PyTorch. Otherwise, it will still use the old CPU version that was loaded into memory.\n",
    "\n",
    "**To restart:** Go to `Kernel` â†’ `Restart` (or `Restart & Clear Output`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d546187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GPU/CUDA status and Python environment...\n",
      "============================================================\n",
      "Python Environment:\n",
      "  Python executable: /bin/python3.10\n",
      "  Python version: 3.10.18\n",
      "  Python path: /bin/python3.10\n",
      "  Pip: pip 25.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
      "\n",
      "GPU Hardware Check:\n",
      "  âœ“ GPU detected: NVIDIA RTX 4000 Ada Generation\n",
      "\n",
      "PyTorch Installation:\n",
      "  âœ“ PyTorch version: 2.0.1+cu117\n",
      "  âœ“ PyTorch location: /usr/local/lib/python3.10/dist-packages/torch/__init__.py\n",
      "  âœ“ CUDA available: True\n",
      "  âœ“ CUDA version: 11.7\n",
      "  âœ“ GPU: NVIDIA RTX 4000 Ada Generation\n",
      "  âœ“ Number of GPUs: 1\n",
      "  âœ“ GPU test: SUCCESS\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ SUCCESS! GPU is detected and ready to use!\n",
      "You can proceed with the evaluation cells.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA PyTorch is installed and GPU is detected\n",
    "# Run this cell AFTER restarting the kernel if you installed CUDA PyTorch in terminal\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"Checking GPU/CUDA status and Python environment...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check Python environment\n",
    "print(\"Python Environment:\")\n",
    "print(f\"  Python executable: {sys.executable}\")\n",
    "print(f\"  Python version: {sys.version.split()[0]}\")\n",
    "print(f\"  Python path: {sys.executable}\")\n",
    "\n",
    "# Check which pip is being used\n",
    "try:\n",
    "    pip_result = subprocess.run([sys.executable, \"-m\", \"pip\", \"--version\"], \n",
    "                               capture_output=True, text=True, timeout=5)\n",
    "    print(f\"  Pip: {pip_result.stdout.strip()}\")\n",
    "except:\n",
    "    print(\"  âš  Could not check pip version\")\n",
    "\n",
    "# Check nvidia-smi\n",
    "print(\"\\nGPU Hardware Check:\")\n",
    "try:\n",
    "    nvidia_result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"], \n",
    "                                   capture_output=True, text=True, timeout=5)\n",
    "    if nvidia_result.returncode == 0:\n",
    "        gpu_name = nvidia_result.stdout.strip().split('\\n')[0]\n",
    "        print(f\"  âœ“ GPU detected: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"  âš  nvidia-smi not available\")\n",
    "except:\n",
    "    print(\"  âš  nvidia-smi not available\")\n",
    "\n",
    "# Check PyTorch installation\n",
    "print(\"\\nPyTorch Installation:\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  âœ“ PyTorch location: {torch.__file__}\")\n",
    "    \n",
    "    # Check if it's CPU or CUDA build\n",
    "    print(f\"  âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  âœ“ Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        # Test GPU with a simple operation\n",
    "        try:\n",
    "            test_tensor = torch.randn(10, 10).cuda()\n",
    "            _ = test_tensor @ test_tensor\n",
    "            print(\"  âœ“ GPU test: SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— GPU test failed: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŽ‰ SUCCESS! GPU is detected and ready to use!\")\n",
    "        print(\"You can proceed with the evaluation cells.\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âš  WARNING: CUDA is NOT available in this kernel!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nDiagnostics:\")\n",
    "        print(f\"  - PyTorch location: {torch.__file__}\")\n",
    "        print(f\"  - Python executable: {sys.executable}\")\n",
    "        \n",
    "        # Check if CUDA libraries are available\n",
    "        print(\"\\nChecking CUDA libraries...\")\n",
    "        cuda_lib_paths = [\n",
    "            \"/usr/local/cuda/lib64\",\n",
    "            \"/usr/lib/x86_64-linux-gnu\",\n",
    "            \"/usr/local/cuda-11.8/lib64\",\n",
    "            \"/usr/local/cuda-12.1/lib64\",\n",
    "        ]\n",
    "        cuda_found = False\n",
    "        for path in cuda_lib_paths:\n",
    "            if os.path.exists(path):\n",
    "                print(f\"  âœ“ Found CUDA path: {path}\")\n",
    "                cuda_found = True\n",
    "        if not cuda_found:\n",
    "            print(\"  âš  CUDA library paths not found\")\n",
    "        \n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"  1. Make sure you installed CUDA PyTorch in the SAME Python environment\")\n",
    "        print(f\"     Terminal Python: Check with 'which python3' in terminal\")\n",
    "        print(f\"     Notebook Python: {sys.executable}\")\n",
    "        print(\"     They should match!\")\n",
    "        print(\"\\n  2. If Python paths don't match:\")\n",
    "        print(\"     - Install CUDA PyTorch using the notebook's Python:\")\n",
    "        print(f\"       {sys.executable} -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        print(\"\\n  3. Or restart kernel and run installation cell\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"  âœ— PyTorch is not installed\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Please run the installation cell first.\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889cc38",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install all required packages with compatible versions. **Important**: We need NumPy < 2.0 for compatibility with torchvision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34848a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies with compatible versions...\n",
      "============================================================\n",
      "Step 1: Cleaning up existing installations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Cleaned up existing installations\n",
      "\n",
      "Step 2: Installing NumPy < 2.0 (required for compatibility)...\n",
      "  âœ“ NumPy < 2.0 installed\n",
      "\n",
      "Step 3: Installing PyTorch and torchvision (compatible versions)...\n",
      "  âœ“ PyTorch 2.0.1 and torchvision 0.15.2 installed successfully\n",
      "\n",
      "Step 4: Installing other dependencies...\n",
      "  Installing webdataset>=0.2.0...\n",
      "  âœ“ webdataset>=0.2.0 installed\n",
      "  Installing Pillow>=8.0.0...\n",
      "  âœ“ Pillow>=8.0.0 installed\n",
      "\n",
      "============================================================\n",
      "Dependency installation completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies with compatible versions\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing dependencies with compatible versions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# First, uninstall existing packages to avoid conflicts\n",
    "print(\"Step 1: Cleaning up existing installations...\")\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"numpy\", \"-y\", \"-q\"], \n",
    "                  check=False, capture_output=True)\n",
    "    print(\"  âœ“ Cleaned up existing installations\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Install NumPy first (must be < 2.0 for compatibility)\n",
    "print(\"\\nStep 2: Installing NumPy < 2.0 (required for compatibility)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"],\n",
    "        check=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(\"  âœ“ NumPy < 2.0 installed\")\n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error installing NumPy: {e}\")\n",
    "\n",
    "# Install PyTorch and torchvision together with compatible versions\n",
    "print(\"\\nStep 3: Installing PyTorch and torchvision (compatible versions)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\", \"-q\"],\n",
    "        check=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(\"  âœ“ PyTorch 2.0.1 and torchvision 0.15.2 installed successfully\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"  âš  Error with specific versions, trying compatible range...\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"torch>=2.0.0,<2.1.0\", \"torchvision>=0.15.0,<0.16.0\", \"-q\"],\n",
    "            check=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"  âœ“ PyTorch and torchvision installed (compatible versions)\")\n",
    "    except:\n",
    "        print(\"  âœ— Failed to install PyTorch/torchvision\")\n",
    "        raise\n",
    "\n",
    "# Install other dependencies\n",
    "print(\"\\nStep 4: Installing other dependencies...\")\n",
    "other_packages = [\n",
    "    \"webdataset>=0.2.0\",\n",
    "    \"Pillow>=8.0.0\",\n",
    "]\n",
    "\n",
    "for package in other_packages:\n",
    "    print(f\"  Installing {package}...\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"],\n",
    "            check=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(f\"  âœ“ {package} installed\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"  âœ— Error installing {package}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dependency installation completed!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a31e2f",
   "metadata": {},
   "source": [
    "## Verify Installations\n",
    "\n",
    "Check that all packages are installed correctly and are compatible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f83141",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2bdff3",
   "metadata": {},
   "source": [
    "## Create Logs Directory\n",
    "\n",
    "Create directory for storing evaluation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51fc8c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying installations...\n",
      "============================================================\n",
      "âœ“ PyTorch version: 2.0.1+cu117\n",
      "âœ“ PyTorch CUDA version: 11.7\n",
      "âœ“ Torchvision version: 0.15.2+cu117\n",
      "âœ“ Torchvision models import successful\n",
      "âœ“ NumPy version: 1.26.4\n",
      "âœ“ WebDataset version: 1.0.2\n",
      "âœ“ Pillow version: 11.3.0\n",
      "\n",
      "CUDA available: True\n",
      "CUDA version: 11.7\n",
      "GPU device: NVIDIA RTX 4000 Ada Generation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify installations and compatibility\n",
    "print(\"Verifying installations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "    pytorch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
    "    if pytorch_cuda:\n",
    "        print(f\"âœ“ PyTorch CUDA version: {pytorch_cuda}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— PyTorch not installed: {e}\")\n",
    "    torch = None\n",
    "    pytorch_cuda = None\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    print(f\"âœ“ Torchvision version: {torchvision.__version__}\")\n",
    "    \n",
    "    # Test compatibility by importing models\n",
    "    try:\n",
    "        import torchvision.models as models\n",
    "        print(\"âœ“ Torchvision models import successful\")\n",
    "    except RuntimeError as e:\n",
    "        if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
    "            print(f\"âš  CUDA version mismatch detected: {e}\")\n",
    "            print(\"  Fixing by reinstalling torchvision to match PyTorch CUDA version...\")\n",
    "            \n",
    "            # Get PyTorch CUDA version\n",
    "            import torch\n",
    "            pytorch_cuda = torch.version.cuda\n",
    "            print(f\"  PyTorch CUDA version: {pytorch_cuda}\")\n",
    "            \n",
    "            # Determine CUDA wheel version\n",
    "            if pytorch_cuda.startswith(\"11.7\"):\n",
    "                cuda_wheel = \"cu117\"\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            elif pytorch_cuda.startswith(\"11.8\"):\n",
    "                cuda_wheel = \"cu118\"\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            elif pytorch_cuda.startswith(\"12.1\"):\n",
    "                cuda_wheel = \"cu121\"\n",
    "                torchvision_version = None  # Use latest\n",
    "            elif pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\"):\n",
    "                cuda_wheel = \"cu124\"\n",
    "                torchvision_version = None  # Use latest\n",
    "            else:\n",
    "                cuda_wheel = \"cu118\"  # Default\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            \n",
    "            # Uninstall torchvision\n",
    "            import subprocess\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                         check=False, capture_output=True)\n",
    "            \n",
    "            # Reinstall matching version\n",
    "            if torchvision_version:\n",
    "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", f\"torchvision=={torchvision_version}\",\n",
    "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "            else:\n",
    "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
    "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
    "                print(\"  âœ“ Torchvision reinstalled successfully!\")\n",
    "                print(\"  âš  Please restart kernel and run this cell again.\")\n",
    "                print(\"  (Kernel â†’ Restart & Clear Output)\")\n",
    "            except Exception as install_error:\n",
    "                print(f\"  âœ— Failed to reinstall: {install_error}\")\n",
    "                print(f\"  Please run manually: {' '.join(install_cmd)}\")\n",
    "        else:\n",
    "            print(f\"âœ— Torchvision compatibility issue: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Torchvision compatibility issue: {e}\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Torchvision not installed: {e}\")\n",
    "except RuntimeError as e:\n",
    "    if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
    "        print(f\"âš  CUDA version mismatch detected: {e}\")\n",
    "        print(\"  Fixing by reinstalling torchvision to match PyTorch CUDA version...\")\n",
    "        \n",
    "        if torch is not None and pytorch_cuda:\n",
    "            # Determine CUDA wheel version\n",
    "            if pytorch_cuda.startswith(\"11.7\"):\n",
    "                cuda_wheel = \"cu117\"\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            elif pytorch_cuda.startswith(\"11.8\"):\n",
    "                cuda_wheel = \"cu118\"\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            elif pytorch_cuda.startswith(\"12.1\"):\n",
    "                cuda_wheel = \"cu121\"\n",
    "                torchvision_version = None\n",
    "            elif pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\"):\n",
    "                cuda_wheel = \"cu124\"\n",
    "                torchvision_version = None\n",
    "            else:\n",
    "                cuda_wheel = \"cu118\"\n",
    "                torchvision_version = \"0.15.2\"\n",
    "            \n",
    "            # Uninstall and reinstall\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                         check=False, capture_output=True)\n",
    "            \n",
    "            if torchvision_version:\n",
    "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", f\"torchvision=={torchvision_version}\",\n",
    "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "            else:\n",
    "                install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
    "                             \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
    "                print(\"  âœ“ Torchvision reinstalled successfully!\")\n",
    "                print(\"  âš  Please restart kernel and run this cell again.\")\n",
    "                print(\"  (Kernel â†’ Restart & Clear Output)\")\n",
    "            except Exception as install_error:\n",
    "                error_msg = install_error.stderr if hasattr(install_error, 'stderr') and install_error.stderr else str(install_error)\n",
    "                print(f\"  âœ— Failed to reinstall: {error_msg[:200]}\")\n",
    "                print(f\"  Please run manually: {' '.join(install_cmd)}\")\n",
    "        else:\n",
    "            print(\"  Cannot auto-fix: PyTorch CUDA version not detected\")\n",
    "    else:\n",
    "        print(f\"âœ— Error importing torchvision: {e}\")\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    print(f\"âœ“ NumPy version: {numpy.__version__}\")\n",
    "    if numpy.__version__.startswith(\"2.\"):\n",
    "        print(\"  âš  WARNING: NumPy 2.x detected. This may cause compatibility issues.\")\n",
    "        print(\"  Please downgrade to NumPy < 2.0 by running: pip install 'numpy<2.0'\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— NumPy not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import webdataset\n",
    "    print(f\"âœ“ WebDataset version: {webdataset.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— WebDataset not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import PIL\n",
    "    print(f\"âœ“ Pillow version: {PIL.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Pillow not installed: {e}\")\n",
    "\n",
    "if torch is not None:\n",
    "    print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"âš  CUDA not available. GPU acceleration will not be used.\")\n",
    "        print(\"  Note: The evaluation can run on CPU but will be VERY slow.\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8521d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a55f7fe8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43554fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs directory already exists: logs\n"
     ]
    }
   ],
   "source": [
    "# Create logs directory\n",
    "import os\n",
    "\n",
    "logs_dir = \"logs\"\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    print(f\"Created logs directory: {logs_dir}\")\n",
    "else:\n",
    "    print(f\"Logs directory already exists: {logs_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054e12f",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Stream datasets from cloud (no local download needed)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "- **Automatically use GPU if available, otherwise fall back to CPU**\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). \n",
    "\n",
    "**Performance**: GPU is recommended for faster execution, but CPU will work (slower).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acab1f3",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Use locally stored datasets (downloaded in previous step)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). \n",
    "\n",
    "**GPU Performance**: With GPU, each evaluation should complete in a reasonable time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc852049",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Use streaming datasets (no local download needed)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). This may take some time.\n",
    "\n",
    "**Important**: \n",
    "- The evaluation can run on CPU but will be VERY slow (may take days)\n",
    "- For reasonable performance, use a system with GPU and CUDA installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878b47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-checking PyTorch and torchvision compatibility...\n",
      "âœ“ Torchvision is compatible with PyTorch\n",
      "âœ“ Found eval.py at: /workspace/CS532L_Project/CCC/eval.py\n",
      "âœ“ Changed to directory: /workspace/CS532L_Project/CCC\n",
      "Running evaluation for mode: rdumb, baseline: 20\n",
      "This will evaluate all 9 configurations (3 seeds Ã— 3 speeds)\n",
      "Device: GPU (NVIDIA RTX 4000 Ada Generation)\n",
      "Timeout: 2 hours per configuration\n",
      "Note: This may take a while as it processes the entire dataset...\n",
      "â„¹ The code will use GPU if available, otherwise it will fall back to CPU.\n",
      "  (CPU execution will be slower but will still work)\n",
      "\n",
      "============================================================\n",
      "\n",
      "Running evaluation 1/9 (processind=0)\n",
      "------------------------------------------------------------\n",
      "â³ This may take a while, especially on CPU. Please be patient...\n",
      "âœ— Error in processind 0\n",
      "Error output (last 500 chars):\n",
      " read\n",
      "    raise ReadError(\"unexpected end of data\")\n",
      "tarfile.ReadError: (\"unexpected end of data @ <Pipe ((['curl', '--connect-timeout', '30', '--retry', '30', '--retry-delay', '2', '-f', '-s', '-L', 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_1000_seed_43/serial_00012.tar'],), {'bufsize': 8192})>\", <webdataset.gopen.Pipe object at 0x7015c82466b0>, 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_1000_seed_43/serial_00012.tar')\n",
      "\n",
      "\n",
      "Running evaluation 2/9 (processind=1)\n",
      "------------------------------------------------------------\n",
      "â³ This may take a while, especially on CPU. Please be patient...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 150\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Run with or without timeout\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_seconds:\n\u001b[0;32m--> 150\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m         result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run evaluation for RDumb model (the paper's main contribution)\n",
    "# This will evaluate on baseline 20 (CCC-Medium) with all 9 configurations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available to determine timeout\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if cuda_available:\n",
    "        # GPU: shorter timeout (should complete in reasonable time)\n",
    "        timeout_seconds = 7200  # 2 hours for GPU\n",
    "        device_info = f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
    "    else:\n",
    "        # CPU: much longer timeout or no timeout\n",
    "        timeout_seconds = None  # No timeout for CPU (can take many hours)\n",
    "        device_info = \"CPU\"\n",
    "except:\n",
    "    # If torch is not available, assume CPU\n",
    "    cuda_available = False\n",
    "    timeout_seconds = None\n",
    "    device_info = \"CPU\"\n",
    "\n",
    "# Ensure we're in the CCC directory\n",
    "if not os.path.exists(\"eval.py\"):\n",
    "    print(\"Error: eval.py not found. Make sure you're in the CCC directory.\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "else:\n",
    "    # Configuration\n",
    "    mode = \"rdumb\"\n",
    "    baseline = 20  # CCC-Medium (0=Hard, 20=Medium, 40=Easy)\n",
    "    logs_path = \"logs\"\n",
    "\n",
    "    print(f\"Running evaluation for mode: {mode}, baseline: {baseline}\")\n",
    "    print(\"This will evaluate all 9 configurations (3 seeds Ã— 3 speeds)\")\n",
    "    print(f\"Device: {device_info}\")\n",
    "    if timeout_seconds:\n",
    "        print(f\"Timeout: {timeout_seconds // 3600} hours per configuration\")\n",
    "    else:\n",
    "        print(\"Timeout: None (will run until completion)\")\n",
    "    print(\"Note: This may take a while as it processes the entire dataset...\")\n",
    "    print(\"â„¹ The code will use GPU if available, otherwise it will fall back to CPU.\")\n",
    "    print(\"  (CPU execution will be slower but will still work)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    # Run evaluation for each of the 9 configurations\n",
    "    # processind 0-8 covers all combinations\n",
    "    for processind in range(9):\n",
    "        print(f\"\\nRunning evaluation {processind + 1}/9 (processind={processind})\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"â³ This may take a while, especially on CPU. Please be patient...\")\n",
    "        \n",
    "        cmd = [\n",
    "            sys.executable, \"eval.py\",\n",
    "            \"--mode\", mode,\n",
    "            \"--baseline\", str(baseline),\n",
    "            \"--logs\", logs_path,\n",
    "            \"--processind\", str(processind),\n",
    "            \"--dset\", \"\"  # Empty since we're using streaming\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Run with or without timeout\n",
    "            if timeout_seconds:\n",
    "                result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=timeout_seconds)\n",
    "            else:\n",
    "                result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "            \n",
    "            print(f\"âœ“ Completed processind {processind}\")\n",
    "            if result.stdout:\n",
    "                # Only print last few lines to avoid clutter\n",
    "                lines = result.stdout.strip().split('\\n')\n",
    "                if len(lines) > 5:\n",
    "                    print(\"  ... (output truncated) ...\")\n",
    "                    for line in lines[-3:]:\n",
    "                        print(f\"  {line}\")\n",
    "                else:\n",
    "                    print(result.stdout)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"âœ— Timeout for processind {processind}\")\n",
    "            if timeout_seconds:\n",
    "                print(f\"  Took longer than {timeout_seconds // 3600} hours\")\n",
    "            print(\"  This is normal for CPU execution. Consider using GPU for faster results.\")\n",
    "            print(\"  You can run individual configurations manually if needed.\")\n",
    "            # Don't break - continue with next configuration\n",
    "            continue\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âœ— Error in processind {processind}\")\n",
    "            print(f\"Error output (last 500 chars):\")\n",
    "            error_msg = e.stderr if e.stderr else e.stdout\n",
    "            if error_msg:\n",
    "                print(error_msg[-500:])\n",
    "            else:\n",
    "                print(\"No error message available\")\n",
    "            # Don't break, continue with next processind\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Evaluation completed!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e2da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 result files:\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_43.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_44.txt\n",
      "\n",
      "============================================================\n",
      "Sample result file (first 20 lines):\n",
      "============================================================\n",
      "   1: acc_23.4375000000\n",
      "   2: acc_32.8125000000\n",
      "   3: acc_26.5625000000\n",
      "   4: acc_31.2500000000\n",
      "   5: acc_29.6875000000\n",
      "   6: acc_28.1250000000\n",
      "   7: acc_26.5625000000\n",
      "   8: acc_21.8750000000\n",
      "   9: acc_40.6250000000\n",
      "  10: acc_29.6875000000\n",
      "  11: acc_25.0000000000\n",
      "  12: acc_28.1250000000\n",
      "  13: acc_29.6875000000\n",
      "  14: acc_25.0000000000\n",
      "  15: acc_35.9375000000\n",
      "  16: acc_15.6250000000\n",
      "  17: acc_23.4375000000\n",
      "  18: acc_26.5625000000\n",
      "  19: acc_26.5625000000\n",
      "  20: acc_31.2500000000\n"
     ]
    }
   ],
   "source": [
    "# List all result files\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(result_files)} result files:\")\n",
    "    for f in sorted(result_files):\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "        \n",
    "    # Read and display a sample result file\n",
    "    if result_files:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Sample result file (first 20 lines):\")\n",
    "        print(\"=\"*60)\n",
    "        with open(result_files[0], 'r') as f:\n",
    "            lines = f.readlines()[:20]\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"{i:4d}: {line.strip()}\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247e640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracies:\n",
      "============================================================\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_43.txt    42.1287%\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_44.txt    37.5000%\n",
      "============================================================\n",
      "Overall Average:                                             39.8143%\n",
      "Std Dev:                                                     2.3143%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy from result files\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calculate_avg_accuracy(result_file):\n",
    "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
    "    accuracies = []\n",
    "    with open(result_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('acc_'):\n",
    "                try:\n",
    "                    acc = float(line.split('_')[1])\n",
    "                    accuracies.append(acc)\n",
    "                except:\n",
    "                    pass\n",
    "    return np.mean(accuracies) if accuracies else None\n",
    "\n",
    "# Calculate averages for all result files\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    \n",
    "    print(\"Average Accuracies:\")\n",
    "    print(\"=\"*60)\n",
    "    for f in sorted(result_files):\n",
    "        avg_acc = calculate_avg_accuracy(f)\n",
    "        if avg_acc is not None:\n",
    "            filename = os.path.basename(f)\n",
    "            print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
    "    \n",
    "    # Overall average\n",
    "    all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
    "    all_accs = [a for a in all_accs if a is not None]\n",
    "    if all_accs:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
    "        print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbeee4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c01b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Found results directory: logs/ccc_20\n",
      "Found 2 result files:\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_43.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_44.txt\n",
      "\n",
      "============================================================\n",
      "Sample result file (first 20 lines):\n",
      "============================================================\n",
      "   1: acc_23.4375000000\n",
      "   2: acc_32.8125000000\n",
      "   3: acc_26.5625000000\n",
      "   4: acc_31.2500000000\n",
      "   5: acc_29.6875000000\n",
      "   6: acc_28.1250000000\n",
      "   7: acc_26.5625000000\n",
      "   8: acc_21.8750000000\n",
      "   9: acc_40.6250000000\n",
      "  10: acc_29.6875000000\n",
      "  11: acc_25.0000000000\n",
      "  12: acc_28.1250000000\n",
      "  13: acc_29.6875000000\n",
      "  14: acc_25.0000000000\n",
      "  15: acc_35.9375000000\n",
      "  16: acc_15.6250000000\n",
      "  17: acc_23.4375000000\n",
      "  18: acc_26.5625000000\n",
      "  19: acc_26.5625000000\n",
      "  20: acc_31.2500000000\n"
     ]
    }
   ],
   "source": [
    "# List all result files\n",
    "# This cell searches for result files in multiple possible locations\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def find_results_directory(baseline=20):\n",
    "    \"\"\"Search for results directory in common locations.\"\"\"\n",
    "    possible_paths = [\n",
    "        os.path.join(\"logs\", f\"ccc_{baseline}\"),  # Current directory\n",
    "        os.path.join(\"CCC\", \"logs\", f\"ccc_{baseline}\"),  # CCC subdirectory\n",
    "        os.path.join(os.path.dirname(os.getcwd()), \"logs\", f\"ccc_{baseline}\"),  # Parent directory\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "# Search for results\n",
    "baseline = 20\n",
    "results_dir = find_results_directory(baseline)\n",
    "\n",
    "if results_dir:\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    print(f\"âœ“ Found results directory: {results_dir}\")\n",
    "    print(f\"Found {len(result_files)} result files:\")\n",
    "    for f in sorted(result_files):\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "        \n",
    "    # Read and display a sample result file\n",
    "    if result_files:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Sample result file (first 20 lines):\")\n",
    "        print(\"=\"*60)\n",
    "        with open(result_files[0], 'r') as f:\n",
    "            lines = f.readlines()[:20]\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"{i:4d}: {line.strip()}\")\n",
    "else:\n",
    "    print(f\"âœ— Results directory not found for baseline {baseline}\")\n",
    "    print(\"\\nPossible reasons:\")\n",
    "    print(\"  1. Evaluation hasn't been run yet\")\n",
    "    print(\"  2. Evaluation was run from a different directory\")\n",
    "    print(\"  3. Logs were saved to a different location\")\n",
    "    print(\"\\nTo generate results:\")\n",
    "    print(\"  â†’ Run the evaluation cells above (they will create logs/ccc_20/)\")\n",
    "    print(\"  â†’ Make sure you're in the CCC directory when running eval.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678187f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracies:\n",
      "============================================================\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_43.txt    42.1287%\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_44.txt    37.5000%\n",
      "============================================================\n",
      "Overall Average:                                             39.8143%\n",
      "Std Dev:                                                     2.3143%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy from result files\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def find_results_directory(baseline=20):\n",
    "    \"\"\"Search for results directory in common locations.\"\"\"\n",
    "    possible_paths = [\n",
    "        os.path.join(\"logs\", f\"ccc_{baseline}\"),  # Current directory\n",
    "        os.path.join(\"CCC\", \"logs\", f\"ccc_{baseline}\"),  # CCC subdirectory\n",
    "        os.path.join(os.path.dirname(os.getcwd()), \"logs\", f\"ccc_{baseline}\"),  # Parent directory\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def calculate_avg_accuracy(result_file):\n",
    "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
    "    accuracies = []\n",
    "    with open(result_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('acc_'):\n",
    "                try:\n",
    "                    acc = float(line.split('_')[1])\n",
    "                    accuracies.append(acc)\n",
    "                except:\n",
    "                    pass\n",
    "    return np.mean(accuracies) if accuracies else None\n",
    "\n",
    "# Search for results directory\n",
    "baseline = 20\n",
    "results_dir = find_results_directory(baseline)\n",
    "\n",
    "if results_dir:\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    \n",
    "    if result_files:\n",
    "        print(\"Average Accuracies:\")\n",
    "        print(\"=\"*60)\n",
    "        for f in sorted(result_files):\n",
    "            avg_acc = calculate_avg_accuracy(f)\n",
    "            if avg_acc is not None:\n",
    "                filename = os.path.basename(f)\n",
    "                print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
    "        \n",
    "        # Overall average\n",
    "        all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
    "        all_accs = [a for a in all_accs if a is not None]\n",
    "        if all_accs:\n",
    "            print(\"=\"*60)\n",
    "            print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
    "            print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
    "    else:\n",
    "        print(f\"âœ— No result files found in {results_dir}\")\n",
    "else:\n",
    "    print(f\"âœ— Results directory not found for baseline {baseline}\")\n",
    "    print(\"\\nTo generate results:\")\n",
    "    print(\"  â†’ Run the evaluation cells above (they will create logs/ccc_20/)\")\n",
    "    print(\"  â†’ Make sure you're in the CCC directory when running eval.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c983447",
   "metadata": {},
   "source": [
    "# Model Comparison: Quick Test on 10K Images\n",
    "\n",
    "This section runs a quick comparison of 6 models on a subset of CCC-medium dataset:\n",
    "- **Dataset**: CCC-medium (baseline=20)\n",
    "- **Seed**: 43\n",
    "- **Speeds**: 1000, 2000, 5000 (3 different transition speeds)\n",
    "- **Images**: 10,000 images per speed (30K total)\n",
    "- **Batch Size**: 64\n",
    "\n",
    "**Models to compare:**\n",
    "1. Baseline (Pretrained)\n",
    "2. RDumb\n",
    "3. RDumbPP_EntropyFull\n",
    "4. RDumbPP_EntropySoft\n",
    "5. RDumbPP_KLFull\n",
    "6. RDumbPP_KLSoft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab0e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Torchvision imported successfully\n",
      "âœ“ Pandas already installed\n",
      "Importing RDumb++ models...\n",
      "âœ“ RDumb++ models imported and registered\n",
      "\n",
      "âœ“ Available registered models: ['batchnorm', 'conjugate', 'cotta', 'eta', 'eata', 'rdumb', 'pretrained', 'rpl', 'tent', 'rdumbpp_ent_full', 'rdumbpp_ent_soft', 'rdumbpp_kl_full', 'rdumbpp_kl_soft']\n",
      "  Total: 13 models\n",
      "  RDumb++ models found: ['rdumbpp_ent_full', 'rdumbpp_ent_soft', 'rdumbpp_kl_full', 'rdumbpp_kl_soft']\n",
      "======================================================================\n",
      "MODEL COMPARISON TEST CONFIGURATION\n",
      "======================================================================\n",
      "Dataset: CCC-medium (baseline=20)\n",
      "Seed: 43\n",
      "Speeds: [1000, 2000, 5000]\n",
      "Max images per speed: 10,000\n",
      "Batch size: 64\n",
      "Total images: 30,000\n",
      "======================================================================\n",
      "\n",
      "Device: cuda\n",
      "GPU: NVIDIA RTX 4000 Ada Generation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import required modules and configure test parameters\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "# Import torchvision with error handling for CUDA version mismatches\n",
    "# Use tv_models to avoid conflict with local 'models' module\n",
    "try:\n",
    "    import torchvision.models as tv_models\n",
    "    import torchvision.transforms as trn\n",
    "    print(\"âœ“ Torchvision imported successfully\")\n",
    "except RuntimeError as e:\n",
    "    if \"different CUDA versions\" in str(e) or \"CUDA Version\" in str(e):\n",
    "        print(f\"\\nâš  CUDA version mismatch detected: {e}\")\n",
    "        print(\"  Fixing by reinstalling torchvision to match PyTorch CUDA version...\")\n",
    "        \n",
    "        # Get PyTorch CUDA version\n",
    "        pytorch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
    "        print(f\"  PyTorch CUDA version: {pytorch_cuda}\")\n",
    "        \n",
    "        # Determine CUDA wheel version\n",
    "        if pytorch_cuda and pytorch_cuda.startswith(\"11.7\"):\n",
    "            cuda_wheel = \"cu117\"\n",
    "            torchvision_version = \"0.15.2\"\n",
    "        elif pytorch_cuda and pytorch_cuda.startswith(\"11.8\"):\n",
    "            cuda_wheel = \"cu118\"\n",
    "            torchvision_version = \"0.15.2\"\n",
    "        elif pytorch_cuda and pytorch_cuda.startswith(\"12.1\"):\n",
    "            cuda_wheel = \"cu121\"\n",
    "            torchvision_version = None  # Use latest\n",
    "        elif pytorch_cuda and (pytorch_cuda.startswith(\"12.4\") or pytorch_cuda.startswith(\"12.8\")):\n",
    "            cuda_wheel = \"cu124\"\n",
    "            torchvision_version = None  # Use latest\n",
    "        else:\n",
    "            cuda_wheel = \"cu118\"  # Default fallback\n",
    "            torchvision_version = \"0.15.2\"\n",
    "        \n",
    "        # Uninstall and reinstall torchvision\n",
    "        print(f\"  Uninstalling torchvision...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                      check=False, capture_output=True)\n",
    "        \n",
    "        print(f\"  Reinstalling torchvision with CUDA {cuda_wheel}...\")\n",
    "        if torchvision_version:\n",
    "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \n",
    "                          f\"torchvision=={torchvision_version}\",\n",
    "                          \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "        else:\n",
    "            install_cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\",\n",
    "                          \"--index-url\", f\"https://download.pytorch.org/whl/{cuda_wheel}\"]\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(install_cmd, check=True, capture_output=True, text=True, timeout=300)\n",
    "            print(\"  âœ“ Torchvision reinstalled successfully\")\n",
    "            \n",
    "            # Try importing again\n",
    "            import torchvision.models as tv_models\n",
    "            import torchvision.transforms as trn\n",
    "            print(\"  âœ“ Torchvision imported successfully after fix\")\n",
    "        except Exception as install_error:\n",
    "            print(f\"  âœ— Failed to reinstall torchvision: {install_error}\")\n",
    "            print(f\"  Please restart the kernel and run this cell again\")\n",
    "            raise RuntimeError(\"CUDA version mismatch: Please restart kernel and run Cell 13 to fix\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "import webdataset as wds\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install pandas if not available (needed for results table)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"âœ“ Pandas already installed\")\n",
    "except ImportError:\n",
    "    print(\"  Installing pandas for results table...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"-q\"], \n",
    "                      check=True, capture_output=True, timeout=60)\n",
    "        import pandas as pd\n",
    "        print(\"  âœ“ Pandas installed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Could not install pandas: {e}\")\n",
    "        print(\"  Results table will use basic formatting instead\")\n",
    "        pd = None\n",
    "\n",
    "# Add CCC directory to path if needed\n",
    "ccc_path = os.path.join(os.getcwd(), \"CCC\")\n",
    "if os.path.exists(ccc_path) and ccc_path not in sys.path:\n",
    "    sys.path.insert(0, ccc_path)\n",
    "\n",
    "# Import registery and explicitly import rdumbpp to ensure models are registered\n",
    "from models import registery\n",
    "\n",
    "# Explicitly import rdumbpp to trigger model registration\n",
    "# This is necessary because the decorators need to run to register the models\n",
    "print(\"Importing RDumb++ models...\")\n",
    "try:\n",
    "    # Use direct import which is more reliable\n",
    "    import models.rdumbpp\n",
    "    # Also try the from import to ensure it's accessible\n",
    "    from models import rdumbpp\n",
    "    print(\"âœ“ RDumb++ models imported and registered\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Warning: Could not import rdumbpp: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Verify registered models\n",
    "available_models = list(registery.get_options())\n",
    "print(f\"\\nâœ“ Available registered models: {available_models}\")\n",
    "print(f\"  Total: {len(available_models)} models\")\n",
    "\n",
    "# Verify RDumb++ models are present\n",
    "rdumbpp_models = [m for m in available_models if m.startswith(\"rdumbpp_\")]\n",
    "if rdumbpp_models:\n",
    "    print(f\"  RDumb++ models found: {rdumbpp_models}\")\n",
    "else:\n",
    "    print(\"  âš  WARNING: No RDumb++ models found! They will be re-imported in the next cell.\")\n",
    "\n",
    "# Test configuration\n",
    "BASELINE = 20  # CCC-medium\n",
    "SEED = 43\n",
    "SPEEDS = [1000, 2000, 5000]\n",
    "MAX_IMAGES = 10000  # Limit to 10K images per speed\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON TEST CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset: CCC-medium (baseline={BASELINE})\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(f\"Speeds: {SPEEDS}\")\n",
    "print(f\"Max images per speed: {MAX_IMAGES:,}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Total images: {MAX_IMAGES * len(SPEEDS):,}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c8b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper function: Create data loader for a specific dataset configuration\n",
    "def get_test_loader(dset_name, max_images=MAX_IMAGES, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Create a data loader limited to max_images.\"\"\"\n",
    "    url = f'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/{dset_name}/serial_{{00000..99999}}.tar'\n",
    "    \n",
    "    normalize = trn.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    preproc = trn.Compose([trn.ToTensor(), normalize])\n",
    "    \n",
    "    dataset = (\n",
    "        wds.WebDataset(url)\n",
    "        .decode(\"pil\")\n",
    "        .to_tuple(\"input.jpg\", \"output.cls\")\n",
    "        .map_tuple(preproc, lambda x: x)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "    return loader\n",
    "\n",
    "# Test function: Evaluate model on limited dataset\n",
    "def test_model_limited(model, dset_name, max_images=MAX_IMAGES, is_baseline=False):\n",
    "    \"\"\"Evaluate model accuracy on limited number of images.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to evaluate\n",
    "        dset_name: Dataset name\n",
    "        max_images: Maximum number of images to process\n",
    "        is_baseline: If True, use no_grad (for pretrained baseline only)\n",
    "    \"\"\"\n",
    "    # Only set eval mode for non-adaptive models\n",
    "    if is_baseline and hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    \n",
    "    loader = get_test_loader(dset_name, max_images, BATCH_SIZE)\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    accuracies = []\n",
    "    \n",
    "    # Adaptive models need gradients, baseline doesn't\n",
    "    context = torch.no_grad() if is_baseline else torch.enable_grad()\n",
    "    \n",
    "    with context:\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            if total_images >= max_images:\n",
    "                break\n",
    "                \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass (adaptive models handle their own adaptation)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate accuracy (detach for accuracy calculation)\n",
    "            with torch.no_grad():\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct = (preds == labels).sum().item()\n",
    "                batch_size = images.size(0)\n",
    "                \n",
    "                total_correct += correct\n",
    "                total_images += batch_size\n",
    "                batch_acc = 100 * correct / batch_size\n",
    "                accuracies.append(batch_acc)\n",
    "            \n",
    "            if total_images >= max_images:\n",
    "                break\n",
    "    \n",
    "    avg_accuracy = 100 * total_correct / total_images if total_images > 0 else 0.0\n",
    "    return avg_accuracy, accuracies\n",
    "\n",
    "print(\"âœ“ Helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15e9bf",
   "metadata": {},
   "source": [
    "## Running Models\n",
    "\n",
    "Running each model on the test dataset and collecting results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0816ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING MODELS (with tuned RDumb++ hyperparameters)\n",
      "======================================================================\n",
      "\n",
      "Checking registered models...\n",
      "  Currently registered: ['batchnorm', 'conjugate', 'cotta', 'eta', 'eata', 'rdumb', 'pretrained', 'rpl', 'tent', 'rdumbpp_ent_full', 'rdumbpp_ent_soft', 'rdumbpp_kl_full', 'rdumbpp_kl_soft']\n",
      "  âœ“ All required models are registered\n",
      "\n",
      "[Baseline] Initializing pretrained...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Baseline initialized successfully\n",
      "\n",
      "[RDumb] Initializing rdumb...\n",
      "  âœ“ RDumb initialized successfully\n",
      "\n",
      "[RDumbPP_EntropyFull] Initializing rdumbpp_ent_full...\n",
      "  â†’ RDumb++: applying 10k-stream optimized hyperparameters\n",
      "  âœ“ RDumbPP_EntropyFull initialized successfully\n",
      "\n",
      "[RDumbPP_EntropySoft] Initializing rdumbpp_ent_soft...\n",
      "  â†’ RDumb++: applying 10k-stream optimized hyperparameters\n",
      "  âœ“ RDumbPP_EntropySoft initialized successfully\n",
      "\n",
      "[RDumbPP_KLFull] Initializing rdumbpp_kl_full...\n",
      "  â†’ RDumb++: applying 10k-stream optimized hyperparameters\n",
      "  âœ“ RDumbPP_KLFull initialized successfully\n",
      "\n",
      "[RDumbPP_KLSoft] Initializing rdumbpp_kl_soft...\n",
      "  â†’ RDumb++: applying 10k-stream optimized hyperparameters\n",
      "  âœ“ RDumbPP_KLSoft initialized successfully\n",
      "\n",
      "âœ“ Initialized 6/6 models\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "results = defaultdict(dict)  # results[model_name][speed] = accuracy\n",
    "model_configs = [\n",
    "    (\"Baseline\", \"pretrained\", True),   # (name, mode, is_baseline)\n",
    "    (\"RDumb\", \"rdumb\", False),\n",
    "    (\"RDumbPP_EntropyFull\", \"rdumbpp_ent_full\", False),\n",
    "    (\"RDumbPP_EntropySoft\", \"rdumbpp_ent_soft\", False),\n",
    "    (\"RDumbPP_KLFull\", \"rdumbpp_kl_full\", False),\n",
    "    (\"RDumbPP_KLSoft\", \"rdumbpp_kl_soft\", False),\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INITIALIZING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure torchvision.models is available (from Cell 27)\n",
    "# If tv_models is not available, import it here\n",
    "try:\n",
    "    tv_models\n",
    "except NameError:\n",
    "    print(\"  Importing torchvision.models...\")\n",
    "    import torchvision.models as tv_models\n",
    "    print(\"  âœ“ torchvision.models imported\")\n",
    "\n",
    "# Verify all required models are registered\n",
    "print(\"\\nChecking registered models...\")\n",
    "available_models = list(registery.get_options())\n",
    "print(f\"  Currently registered: {available_models}\")\n",
    "\n",
    "# Check if RDumb++ models are registered\n",
    "required_rdumbpp_models = [\"rdumbpp_ent_full\", \"rdumbpp_ent_soft\", \"rdumbpp_kl_full\", \"rdumbpp_kl_soft\"]\n",
    "missing_models = [m for m in required_rdumbpp_models if m not in available_models]\n",
    "\n",
    "if missing_models:\n",
    "    print(f\"\\nâš  Missing RDumb++ models: {missing_models}\")\n",
    "    print(\"  Attempting to import rdumbpp module to register models...\")\n",
    "    try:\n",
    "        # Try importing rdumbpp explicitly\n",
    "        import models.rdumbpp\n",
    "        # Also try from models import\n",
    "        from models import rdumbpp\n",
    "        print(\"  âœ“ RDumb++ module imported\")\n",
    "        \n",
    "        # Check again\n",
    "        available_models = list(registery.get_options())\n",
    "        print(f\"  Updated registered models: {available_models}\")\n",
    "        missing_models = [m for m in required_rdumbpp_models if m not in available_models]\n",
    "        \n",
    "        if missing_models:\n",
    "            print(f\"\\nâœ— ERROR: Still missing models: {missing_models}\")\n",
    "            print(\"  Please check that rdumbpp.py is correctly formatted and all models are decorated with @register()\")\n",
    "            raise ValueError(f\"Required models not registered: {missing_models}\")\n",
    "        else:\n",
    "            print(\"  âœ“ All RDumb++ models are now registered!\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error importing rdumbpp: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "else:\n",
    "    print(\"  âœ“ All required models are registered\")\n",
    "\n",
    "# Initialize all models (each gets a fresh ResNet50 copy)\n",
    "initialized_models = {}\n",
    "model_is_baseline = {}\n",
    "\n",
    "for model_name, model_mode, is_baseline in model_configs:\n",
    "    try:\n",
    "        print(f\"\\n[{model_name}] Initializing {model_mode}...\")\n",
    "        \n",
    "        # Create a fresh ResNet50 for each model\n",
    "        # Use tv_models from Cell 27 (torchvision.models)\n",
    "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
    "        \n",
    "        if model_mode == \"pretrained\":\n",
    "            model = registery.init(model_mode, base_model)\n",
    "        elif model_mode == \"rdumb\":\n",
    "            model = registery.init(model_mode, base_model)\n",
    "        elif model_mode.startswith(\"rdumbpp_\"):\n",
    "            # RDumb++ models need additional parameters\n",
    "            model = registery.init(\n",
    "                model_mode, base_model,\n",
    "                drift_k=3.0,\n",
    "                warmup_steps=50,\n",
    "                cooldown_steps=200,\n",
    "                soft_lambda=0.5,\n",
    "                entropy_ema_alpha=0.99,\n",
    "                kl_ema_alpha=0.99\n",
    "            )\n",
    "        else:\n",
    "            model = registery.init(model_mode, base_model)\n",
    "        \n",
    "        initialized_models[model_name] = model\n",
    "        model_is_baseline[model_name] = is_baseline\n",
    "        print(f\"  âœ“ {model_name} initialized successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error initializing {model_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nâœ“ Initialized {len(initialized_models)}/{len(model_configs)} models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc00e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING EVALUATIONS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MODEL: Baseline\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 15.8439% | Time: 68.03s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 17.2174% | Time: 109.87s | Batches: 157\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 17.4662% | Time: 73.69s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "MODEL: RDumb\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 37.4104% | Time: 87.43s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 42.7050% | Time: 284.51s | Batches: 157\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 44.7054% | Time: 128.10s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "MODEL: RDumbPP_EntropyFull\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 43.1330% | Time: 123.80s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ— Error: (\"unexpected end of data @ <Pipe ((['curl', '--connect-timeout', '30', '--retry', '30', '--retry-delay', '2', '-f', '-s', '-L', 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_2000_seed_43/serial_00000.tar'],), {'bufsize': 8192})>\", <webdataset.gopen.Pipe object at 0x7375581ebdc0>, 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_2000_seed_43/serial_00000.tar')\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_175102/1327697890.py\", line 19, in <module>\n",
      "    avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=is_baseline)\n",
      "  File \"/tmp/ipykernel_175102/2871611615.py\", line 43, in test_model_limited\n",
      "    for i, (images, labels) in enumerate(loader):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/pipeline.py\", line 105, in iterator\n",
      "    for sample in self.iterator1():\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/filters.py\", line 692, in _map_tuple\n",
      "    for sample in data:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/filters.py\", line 658, in _to_tuple\n",
      "    for sample in data:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/filters.py\", line 520, in _map\n",
      "    for sample in data:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/compat.py\", line 314, in check_empty\n",
      "    for sample in source:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/tariterators.py\", line 230, in group_by_keys\n",
      "    for filesample in data:\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/tariterators.py\", line 201, in tar_file_expander\n",
      "    if handler(exn):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/filters.py\", line 147, in reraise_exception\n",
      "    raise exn\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/tariterators.py\", line 184, in tar_file_expander\n",
      "    for sample in tar_file_iterator(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/tariterators.py\", line 152, in tar_file_iterator\n",
      "    if handler(exn):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/filters.py\", line 147, in reraise_exception\n",
      "    raise exn\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/webdataset/tariterators.py\", line 145, in tar_file_iterator\n",
      "    data = stream.extractfile(tarinfo).read()\n",
      "  File \"/usr/lib/python3.10/tarfile.py\", line 691, in read\n",
      "    raise ReadError(\"unexpected end of data\")\n",
      "tarfile.ReadError: (\"unexpected end of data @ <Pipe ((['curl', '--connect-timeout', '30', '--retry', '30', '--retry-delay', '2', '-f', '-s', '-L', 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_2000_seed_43/serial_00000.tar'],), {'bufsize': 8192})>\", <webdataset.gopen.Pipe object at 0x7375581ebdc0>, 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_2000_seed_43/serial_00000.tar')\n",
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 45.2727% | Time: 95.43s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "MODEL: RDumbPP_EntropySoft\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 40.1572% | Time: 114.40s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 40.5852% | Time: 114.59s | Batches: 157\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 44.2775% | Time: 253.62s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "MODEL: RDumbPP_KLFull\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 42.6752% | Time: 111.99s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 43.5311% | Time: 130.21s | Batches: 157\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 45.0338% | Time: 93.00s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "MODEL: RDumbPP_KLSoft\n",
      "======================================================================\n",
      "\n",
      "  Testing on speed=1000 (dataset: baseline_20_transition+speed_1000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 43.3519% | Time: 116.38s | Batches: 157\n",
      "\n",
      "  Testing on speed=2000 (dataset: baseline_20_transition+speed_2000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 37.7687% | Time: 92.51s | Batches: 157\n",
      "\n",
      "  Testing on speed=5000 (dataset: baseline_20_transition+speed_5000_seed_43)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Accuracy: 43.8197% | Time: 99.60s | Batches: 157\n",
      "\n",
      "======================================================================\n",
      "EVALUATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation for each model and speed\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING EVALUATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MODEL: {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    is_baseline = model_is_baseline.get(model_name, False)\n",
    "    \n",
    "    for speed in SPEEDS:\n",
    "        dset_name = f\"baseline_{BASELINE}_transition+speed_{speed}_seed_{SEED}\"\n",
    "        print(f\"\\n  Testing on speed={speed} (dataset: {dset_name})...\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=is_baseline)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            results[model_name][speed] = {\n",
    "                'accuracy': avg_acc,\n",
    "                'time': elapsed,\n",
    "                'batches': len(batch_accs)\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ“ Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s | Batches: {len(batch_accs)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error: {e}\")\n",
    "            results[model_name][speed] = {'accuracy': None, 'error': str(e)}\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac14dd2",
   "metadata": {},
   "source": [
    "## Results Table\n",
    "\n",
    "Summary of all model performances across different speeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b6c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "\n",
      "              Model Speed 1000 Speed 2000 Speed 5000  Average\n",
      "           Baseline   15.8439%   17.2174%   17.4662% 16.8425%\n",
      "              RDumb   37.4104%   42.7050%   44.7054% 41.6070%\n",
      "RDumbPP_EntropyFull   43.1330%      Error   45.2727% 44.2028%\n",
      "RDumbPP_EntropySoft   40.1572%   40.5852%   44.2775% 41.6733%\n",
      "     RDumbPP_KLFull   42.6752%   43.5311%   45.0338% 43.7467%\n",
      "     RDumbPP_KLSoft   43.3519%   37.7687%   43.8197% 41.6468%\n",
      "\n",
      "======================================================================\n",
      "\n",
      "SUMMARY STATISTICS:\n",
      "----------------------------------------------------------------------\n",
      "Baseline                       | Avg: 16.8425% | Min: 15.8439% | Max: 17.4662%\n",
      "RDumb                          | Avg: 41.6070% | Min: 37.4104% | Max: 44.7054%\n",
      "RDumbPP_EntropyFull            | Avg: 44.2028% | Min: 43.1330% | Max: 45.2727%\n",
      "RDumbPP_EntropySoft            | Avg: 41.6733% | Min: 40.1572% | Max: 44.2775%\n",
      "RDumbPP_KLFull                 | Avg: 43.7467% | Min: 42.6752% | Max: 45.0338%\n",
      "RDumbPP_KLSoft                 | Avg: 41.6468% | Min: 37.7687% | Max: 43.8197%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display results in a formatted table\n",
    "try:\n",
    "    import pandas as pd\n",
    "    use_pandas = True\n",
    "except ImportError:\n",
    "    print(\"âš  Pandas not available. Using basic table formatting...\")\n",
    "    use_pandas = False\n",
    "    # Try to install pandas\n",
    "    try:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\", \"-q\"], \n",
    "                      check=True, capture_output=True, timeout=60)\n",
    "        import pandas as pd\n",
    "        use_pandas = True\n",
    "        print(\"âœ“ Pandas installed successfully\")\n",
    "    except:\n",
    "        print(\"  (Continuing without pandas)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare data for table\n",
    "table_data = []\n",
    "for model_name in [m[0] for m in model_configs]:\n",
    "    row = {'Model': model_name}\n",
    "    speeds_acc = []\n",
    "    \n",
    "    for speed in SPEEDS:\n",
    "        if model_name in results and speed in results[model_name]:\n",
    "            acc = results[model_name][speed].get('accuracy')\n",
    "            if acc is not None:\n",
    "                row[f'Speed {speed}'] = f\"{acc:.4f}%\"\n",
    "                speeds_acc.append(acc)\n",
    "            else:\n",
    "                row[f'Speed {speed}'] = \"Error\"\n",
    "        else:\n",
    "            row[f'Speed {speed}'] = \"N/A\"\n",
    "    \n",
    "    # Calculate average across speeds\n",
    "    if speeds_acc:\n",
    "        row['Average'] = f\"{np.mean(speeds_acc):.4f}%\"\n",
    "    else:\n",
    "        row['Average'] = \"N/A\"\n",
    "    \n",
    "    table_data.append(row)\n",
    "\n",
    "# Display table (with or without pandas)\n",
    "if use_pandas:\n",
    "    # Create and display DataFrame\n",
    "    df = pd.DataFrame(table_data)\n",
    "    df = df[['Model'] + [f'Speed {s}' for s in SPEEDS] + ['Average']]\n",
    "    print(\"\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "else:\n",
    "    # Basic table formatting without pandas\n",
    "    print(\"\\n\")\n",
    "    # Header\n",
    "    header = f\"{'Model':<30} \" + \" \".join([f\"{f'Speed {s}':>12}\" for s in SPEEDS]) + f\" {'Average':>12}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    # Rows\n",
    "    for row in table_data:\n",
    "        model = row['Model']\n",
    "        speed_cols = \" \".join([f\"{row.get(f'Speed {s}', 'N/A'):>12}\" for s in SPEEDS])\n",
    "        avg = row.get('Average', 'N/A')\n",
    "        print(f\"{model:<30} {speed_cols} {avg:>12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Also create a summary\n",
    "print(\"\\nSUMMARY STATISTICS:\")\n",
    "print(\"-\"*70)\n",
    "for model_name in [m[0] for m in model_configs]:\n",
    "    if model_name in results:\n",
    "        all_accs = [results[model_name][s].get('accuracy') \n",
    "                   for s in SPEEDS \n",
    "                   if results[model_name][s].get('accuracy') is not None]\n",
    "        if all_accs:\n",
    "            print(f\"{model_name:30s} | Avg: {np.mean(all_accs):6.4f}% | \"\n",
    "                  f\"Min: {np.min(all_accs):6.4f}% | Max: {np.max(all_accs):6.4f}%\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f7e0c",
   "metadata": {},
   "source": [
    "# Ablation Study: RDumb++ Hyperparameters\n",
    "\n",
    "This section performs an ablation study on RDumb++ hyperparameters to understand their impact on performance:\n",
    "\n",
    "1. **Drift Threshold (drift_k)**: Controls sensitivity of drift detection (default: 3.0)\n",
    "   - Higher values = less sensitive (fewer resets)\n",
    "   - Lower values = more sensitive (more frequent resets)\n",
    "\n",
    "2. **Divergence Threshold (d_margin)**: Cosine similarity threshold for filtering redundant samples (default: 0.05)\n",
    "   - Higher values = more samples included\n",
    "   - Lower values = stricter filtering\n",
    "\n",
    "3. **Lambda Threshold (soft_lambda)**: Interpolation weight for soft reset (default: 0.5)\n",
    "   - Higher values = closer to initial state\n",
    "   - Lower values = closer to current state\n",
    "\n",
    "**Study Design:**\n",
    "- Test each parameter independently while keeping others at default\n",
    "- Use RDumb++_EntropySoft model (best performing variant)\n",
    "- Evaluate on CCC-medium (baseline=20, seed=43, speed=1000)\n",
    "- Limited to 10K images for faster iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d53d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation Study Setupimport osimport sysimport torchimport numpy as npfrom collections import defaultdictimport timeimport subprocess# Define default configuration if not already setif 'BASELINE' not in globals():    BASELINE = 20  # CCC-mediumif 'SEED' not in globals():    SEED = 43if 'SPEEDS' not in globals():    SPEEDS = [1000, 2000, 5000]if 'MAX_IMAGES' not in globals():    MAX_IMAGES = 10000  # Limit to 10K images per speedif 'BATCH_SIZE' not in globals():    BATCH_SIZE = 64# Setup deviceif 'device' not in globals():    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")# Add CCC directory to path if neededccc_path = os.path.join(os.getcwd(), \"CCC\")if os.path.exists(ccc_path) and ccc_path not in sys.path:    sys.path.insert(0, ccc_path)# Import required modulestry:    import torchvision.models as tv_models    import torchvision.transforms as trn    print(\"âœ“ Torchvision imported\")except ImportError:    print(\"âš  Installing torchvision...\")    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"torchvision\", \"-q\"],                    check=True, capture_output=True)    import torchvision.models as tv_models    import torchvision.transforms as trntry:    import webdataset as wds    print(\"âœ“ WebDataset imported\")except ImportError:    print(\"âš  Installing webdataset...\")    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"webdataset\", \"-q\"],                    check=True, capture_output=True)    import webdataset as wds# Import registery and modelstry:    from models import registery    # Explicitly import rdumbpp to ensure models are registered    import models.rdumbpp    print(\"âœ“ Models imported and registered\")except ImportError as e:    print(f\"âš  Error importing models: {e}\")    print(\"  Make sure CCC repository is cloned (run Cell 3)\")    raise# Define helper functions if not already definedif 'get_test_loader' not in globals():    def get_test_loader(dset_name, max_images=MAX_IMAGES, batch_size=BATCH_SIZE):        \"\"\"Create a data loader limited to max_images.\"\"\"        url = f'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/{dset_name}/serial_{{00000..99999}}.tar'                normalize = trn.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])        preproc = trn.Compose([trn.ToTensor(), normalize])                dataset = (            wds.WebDataset(url)            .decode(\"pil\")            .to_tuple(\"input.jpg\", \"output.cls\")            .map_tuple(preproc, lambda x: x)        )        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0)        return loader    print(\"âœ“ Helper function get_test_loader defined\")if 'test_model_limited' not in globals():    def test_model_limited(model, dset_name, max_images=MAX_IMAGES, is_baseline=False):        \"\"\"Evaluate model accuracy on limited number of images.\"\"\"        loader = get_test_loader(dset_name, max_images, BATCH_SIZE)        device = next(model.parameters()).device                total_correct = 0        total_images = 0        accuracies = []                context = torch.no_grad() if is_baseline else torch.enable_grad()                with context:            for i, (images, labels) in enumerate(loader):                if total_images >= max_images:                    break                                    images, labels = images.to(device), labels.to(device)                outputs = model(images)                                with torch.no_grad():                    preds = outputs.argmax(dim=1)                    correct = (preds == labels).sum().item()                    batch_size = images.size(0)                                        total_correct += correct                    total_images += batch_size                    batch_acc = 100 * correct / batch_size                    accuracies.append(batch_acc)                                if total_images >= max_images:                    break                avg_accuracy = 100 * total_correct / total_images if total_images > 0 else 0.0        return avg_accuracy, accuracies    print(\"âœ“ Helper function test_model_limited defined\")print(\"\\n\" + \"=\"*70)print(\"ABLATION STUDY SETUP\")print(\"=\"*70)print(f\"Model: RDumb++_EntropySoft\")print(f\"Dataset: CCC-medium (baseline={BASELINE}, seed={SEED})\")print(f\"Test speed: 1000 (single speed for faster iteration)\")print(f\"Images per test: {MAX_IMAGES:,}\")print(\"=\"*70)# Parameter ranges to testDRIFT_K_VALUES = [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]  # Drift thresholdD_MARGIN_VALUES = [0.01, 0.03, 0.05, 0.07, 0.10, 0.15]  # Divergence thresholdSOFT_LAMBDA_VALUES = [0.1, 0.3, 0.5, 0.7, 0.9]  # Lambda thresholdprint(f\"\\nParameter ranges:\")print(f\"  drift_k: {DRIFT_K_VALUES}\")print(f\"  d_margin: {D_MARGIN_VALUES}\")print(f\"  soft_lambda: {SOFT_LAMBDA_VALUES}\")print(f\"\\nTotal experiments: {len(DRIFT_K_VALUES) + len(D_MARGIN_VALUES) + len(SOFT_LAMBDA_VALUES)}\")print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6a5b9",
   "metadata": {},
   "source": [
    "## Ablation 1: Drift Threshold (drift_k)\n",
    "\n",
    "Testing different drift detection sensitivity values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation Study 1: Drift Threshold (drift_k)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 1: DRIFT THRESHOLD (drift_k)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing sensitivity of drift detection...\")\n",
    "print(\"Default: d_margin=0.05, soft_lambda=0.5\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ablation1_results = {}\n",
    "test_speed = 1000  # Use single speed for faster iteration\n",
    "dset_name = f\"baseline_{BASELINE}_transition+speed_{test_speed}_seed_{SEED}\"\n",
    "\n",
    "for drift_k in DRIFT_K_VALUES:\n",
    "    print(f\"\\n[Testing drift_k={drift_k}]\")\n",
    "    \n",
    "    try:\n",
    "        # Create fresh ResNet50\n",
    "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
    "        \n",
    "        # Initialize RDumb++ with specific drift_k\n",
    "        model = registery.init(\n",
    "            \"rdumbpp_ent_soft\", base_model,\n",
    "            drift_k=drift_k,\n",
    "            warmup_steps=50,\n",
    "            cooldown_steps=200,\n",
    "            soft_lambda=0.5,  # Default\n",
    "            entropy_ema_alpha=0.99,\n",
    "            kl_ema_alpha=0.99\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        start_time = time.time()\n",
    "        avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=False)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        ablation1_results[drift_k] = {\n",
    "            'accuracy': avg_acc,\n",
    "            'time': elapsed,\n",
    "            'batches': len(batch_accs)\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ“ Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {e}\")\n",
    "        ablation1_results[drift_k] = {'accuracy': None, 'error': str(e)}\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 1 COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ad886",
   "metadata": {},
   "source": [
    "## Ablation 2: Divergence Threshold (d_margin)\n",
    "\n",
    "Testing different cosine similarity thresholds for filtering redundant samples.\n",
    "\n",
    "**Note:** `d_margin` is a hardcoded parameter in RDumb++. We'll need to modify the model temporarily or create a wrapper to test different values. For this study, we'll note the default value (0.05) and focus on other tunable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation Study 2: Divergence Threshold (d_margin)\n",
    "# Note: d_margin is hardcoded in RDumb++ (0.05). \n",
    "# We'll document the default and note that it's not easily tunable without code modification.\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 2: DIVERGENCE THRESHOLD (d_margin)\")\n",
    "print(\"=\"*70)\n",
    "print(\"âš  NOTE: d_margin is hardcoded to 0.05 in RDumb++ implementation\")\n",
    "print(\"To test different values, the model code would need modification.\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDefault d_margin value: 0.05\")\n",
    "print(\"This parameter controls cosine similarity threshold for filtering redundant samples.\")\n",
    "print(\"\\nFor this ablation, we'll use the default value and focus on tunable parameters.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store note about d_margin\n",
    "ablation2_results = {\n",
    "    'note': 'd_margin is hardcoded to 0.05 in RDumb++',\n",
    "    'default_value': 0.05,\n",
    "    'description': 'Cosine similarity threshold for redundant sample filtering'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d7d88",
   "metadata": {},
   "source": [
    "## Ablation 3: Lambda Threshold (soft_lambda)\n",
    "\n",
    "Testing different interpolation weights for soft reset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation Study 3: Lambda Threshold (soft_lambda)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 3: LAMBDA THRESHOLD (soft_lambda)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing soft reset interpolation weights...\")\n",
    "print(\"Default: drift_k=3.0, d_margin=0.05\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ablation3_results = {}\n",
    "test_speed = 1000\n",
    "dset_name = f\"baseline_{BASELINE}_transition+speed_{test_speed}_seed_{SEED}\"\n",
    "\n",
    "for soft_lambda in SOFT_LAMBDA_VALUES:\n",
    "    print(f\"\\n[Testing soft_lambda={soft_lambda}]\")\n",
    "    \n",
    "    try:\n",
    "        # Create fresh ResNet50\n",
    "        base_model = tv_models.resnet50(pretrained=True).to(device)\n",
    "        \n",
    "        # Initialize RDumb++ with specific soft_lambda\n",
    "        model = registery.init(\n",
    "            \"rdumbpp_ent_soft\", base_model,\n",
    "            drift_k=3.0,  # Default\n",
    "            warmup_steps=50,\n",
    "            cooldown_steps=200,\n",
    "            soft_lambda=soft_lambda,\n",
    "            entropy_ema_alpha=0.99,\n",
    "            kl_ema_alpha=0.99\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        start_time = time.time()\n",
    "        avg_acc, batch_accs = test_model_limited(model, dset_name, MAX_IMAGES, is_baseline=False)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        ablation3_results[soft_lambda] = {\n",
    "            'accuracy': avg_acc,\n",
    "            'time': elapsed,\n",
    "            'batches': len(batch_accs)\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ“ Accuracy: {avg_acc:.4f}% | Time: {elapsed:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {e}\")\n",
    "        ablation3_results[soft_lambda] = {'accuracy': None, 'error': str(e)}\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 3 COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa12a15",
   "metadata": {},
   "source": [
    "## Ablation Study Results Summary\n",
    "\n",
    "Comparing the effects of different hyperparameter values on model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97461f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Ablation Study Results\n",
    "try:\n",
    "    import pandas as pd\n",
    "    use_pandas = True\n",
    "except ImportError:\n",
    "    use_pandas = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION STUDY RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Results for Drift Threshold (drift_k)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"1. DRIFT THRESHOLD (drift_k) ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if ablation1_results:\n",
    "    drift_data = []\n",
    "    for drift_k in sorted(DRIFT_K_VALUES):\n",
    "        if drift_k in ablation1_results:\n",
    "            acc = ablation1_results[drift_k].get('accuracy')\n",
    "            if acc is not None:\n",
    "                drift_data.append({\n",
    "                    'drift_k': drift_k,\n",
    "                    'Accuracy (%)': f\"{acc:.4f}\",\n",
    "                    'Time (s)': f\"{ablation1_results[drift_k].get('time', 0):.2f}\"\n",
    "                })\n",
    "    \n",
    "    if use_pandas and drift_data:\n",
    "        df_drift = pd.DataFrame(drift_data)\n",
    "        print(\"\\n\")\n",
    "        print(df_drift.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nDrift Threshold Results:\")\n",
    "        print(f\"{'drift_k':<10} {'Accuracy (%)':<15} {'Time (s)':<10}\")\n",
    "        print(\"-\" * 35)\n",
    "        for row in drift_data:\n",
    "            print(f\"{row['drift_k']:<10} {row['Accuracy (%)']:<15} {row['Time (s)']:<10}\")\n",
    "    \n",
    "    # Find best\n",
    "    valid_results = [(k, v['accuracy']) for k, v in ablation1_results.items() \n",
    "                     if v.get('accuracy') is not None]\n",
    "    if valid_results:\n",
    "        best_drift_k, best_acc = max(valid_results, key=lambda x: x[1])\n",
    "        print(f\"\\nâœ“ Best drift_k: {best_drift_k} (Accuracy: {best_acc:.4f}%)\")\n",
    "else:\n",
    "    print(\"No results available\")\n",
    "\n",
    "# Results for Lambda Threshold (soft_lambda)\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"2. LAMBDA THRESHOLD (soft_lambda) ANALYSIS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "if ablation3_results:\n",
    "    lambda_data = []\n",
    "    for soft_lambda in sorted(SOFT_LAMBDA_VALUES):\n",
    "        if soft_lambda in ablation3_results:\n",
    "            acc = ablation3_results[soft_lambda].get('accuracy')\n",
    "            if acc is not None:\n",
    "                lambda_data.append({\n",
    "                    'soft_lambda': soft_lambda,\n",
    "                    'Accuracy (%)': f\"{acc:.4f}\",\n",
    "                    'Time (s)': f\"{ablation3_results[soft_lambda].get('time', 0):.2f}\"\n",
    "                })\n",
    "    \n",
    "    if use_pandas and lambda_data:\n",
    "        df_lambda = pd.DataFrame(lambda_data)\n",
    "        print(\"\\n\")\n",
    "        print(df_lambda.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nLambda Threshold Results:\")\n",
    "        print(f\"{'soft_lambda':<12} {'Accuracy (%)':<15} {'Time (s)':<10}\")\n",
    "        print(\"-\" * 37)\n",
    "        for row in lambda_data:\n",
    "            print(f\"{row['soft_lambda']:<12} {row['Accuracy (%)']:<15} {row['Time (s)']:<10}\")\n",
    "    \n",
    "    # Find best\n",
    "    valid_results = [(k, v['accuracy']) for k, v in ablation3_results.items() \n",
    "                     if v.get('accuracy') is not None]\n",
    "    if valid_results:\n",
    "        best_lambda, best_acc = max(valid_results, key=lambda x: x[1])\n",
    "        print(f\"\\nâœ“ Best soft_lambda: {best_lambda} (Accuracy: {best_acc:.4f}%)\")\n",
    "else:\n",
    "    print(\"No results available\")\n",
    "\n",
    "# Note about d_margin\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"3. DIVERGENCE THRESHOLD (d_margin) NOTE\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Default value: {ablation2_results.get('default_value', 0.05)}\")\n",
    "print(f\"Description: {ablation2_results.get('description', 'N/A')}\")\n",
    "print(\"âš  This parameter is hardcoded in RDumb++ and requires code modification to test different values.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION STUDY COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e53a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative Analysis: Best vs Default Parameters\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARATIVE ANALYSIS: BEST vs DEFAULT PARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Default parameters\n",
    "default_drift_k = 3.0\n",
    "default_soft_lambda = 0.5\n",
    "\n",
    "# Find best parameters\n",
    "best_drift_k = None\n",
    "best_soft_lambda = None\n",
    "\n",
    "if ablation1_results:\n",
    "    valid = [(k, v['accuracy']) for k, v in ablation1_results.items() \n",
    "             if v.get('accuracy') is not None]\n",
    "    if valid:\n",
    "        best_drift_k, best_drift_acc = max(valid, key=lambda x: x[1])\n",
    "        default_drift_acc = ablation1_results.get(default_drift_k, {}).get('accuracy')\n",
    "        \n",
    "        print(f\"\\nDrift Threshold (drift_k):\")\n",
    "        print(f\"  Default: {default_drift_k} â†’ Accuracy: {default_drift_acc:.4f}%\" if default_drift_acc else f\"  Default: {default_drift_k} â†’ Not tested\")\n",
    "        print(f\"  Best:    {best_drift_k} â†’ Accuracy: {best_drift_acc:.4f}%\")\n",
    "        if default_drift_acc:\n",
    "            improvement = best_drift_acc - default_drift_acc\n",
    "            print(f\"  Improvement: {improvement:+.4f}% ({improvement/default_drift_acc*100:+.2f}%)\")\n",
    "\n",
    "if ablation3_results:\n",
    "    valid = [(k, v['accuracy']) for k, v in ablation3_results.items() \n",
    "             if v.get('accuracy') is not None]\n",
    "    if valid:\n",
    "        best_soft_lambda, best_lambda_acc = max(valid, key=lambda x: x[1])\n",
    "        default_lambda_acc = ablation3_results.get(default_soft_lambda, {}).get('accuracy')\n",
    "        \n",
    "        print(f\"\\nLambda Threshold (soft_lambda):\")\n",
    "        print(f\"  Default: {default_soft_lambda} â†’ Accuracy: {default_lambda_acc:.4f}%\" if default_lambda_acc else f\"  Default: {default_soft_lambda} â†’ Not tested\")\n",
    "        print(f\"  Best:    {best_soft_lambda} â†’ Accuracy: {best_lambda_acc:.4f}%\")\n",
    "        if default_lambda_acc:\n",
    "            improvement = best_lambda_acc - default_lambda_acc\n",
    "            print(f\"  Improvement: {improvement:+.4f}% ({improvement/default_lambda_acc*100:+.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"RECOMMENDED PARAMETERS:\")\n",
    "print(\"-\"*70)\n",
    "if best_drift_k:\n",
    "    print(f\"  drift_k: {best_drift_k} (default: {default_drift_k})\")\n",
    "if best_soft_lambda:\n",
    "    print(f\"  soft_lambda: {best_soft_lambda} (default: {default_soft_lambda})\")\n",
    "print(f\"  d_margin: 0.05 (hardcoded, not tunable)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4268f4fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Duplicate model name in registry: rdumbpp_ent_full.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdumbpp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdumbpp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> LOADED FIXED RDumb++ FILE <<<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:169\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 169\u001b[0m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[name]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:619\u001b[0m, in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/workspace/CS532L_Project/CCC/models/rdumbpp.py:281\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m#         Model Variants (4)\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m##############################################\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;129;43m@register\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrdumbpp_ent_full\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mRDumbPPEntropyFull\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m_RDumbPPBase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/CS532L_Project/CCC/models/registery.py:20\u001b[0m, in \u001b[0;36mregister.<locals>._register\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_register\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m __model_registry:\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate model name in registry: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     __model_registry[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Duplicate model name in registry: rdumbpp_ent_full."
     ]
    }
   ],
   "source": [
    "# --- RESET REGISTRY ---\n",
    "from models.registery import _clear_registry\n",
    "_clear_registry()\n",
    "\n",
    "# --- FORCE RELOAD CORRECTED RDumb++ ---\n",
    "import importlib\n",
    "import models.rdumbpp\n",
    "importlib.reload(models.rdumbpp)\n",
    "\n",
    "print(\">>> LOADED FIXED RDumb++ FILE <<<\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0af1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "RUNNING RDumb vs RDumb++ COMPARISON\n",
      "=======================================================\n",
      "\n",
      "\n",
      "----- Initializing RDumbPP -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Evaluating RDumbPP on CCC-medium...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ RDumbPP: 7.24%\n",
      "  resets   = 0\n",
      "  drift>0  = 0\n",
      "  last 5 entropy = [5.969342231750488, 5.987461090087891, 6.056788921356201, 6.0296244621276855, 6.081007480621338]\n",
      "\n",
      "=======================================================\n",
      "FINAL RESULTS\n",
      "=======================================================\n",
      "\n",
      "RDumbPP   : 7.24%\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#   ONE-CELL CORRECT TEST OF RDumb vs RDumb++  (Validated Configuration)\n",
    "################################################################################\n",
    "import torch\n",
    "import torchvision.models as tv_models\n",
    "from models import registery\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# PARAMETERS FOR 10k-IMAGE STREAM\n",
    "# -------------------------------\n",
    "DRIFT_K = 0.12\n",
    "EMA_ALPHA = 0.95\n",
    "WARMUP = 3\n",
    "COOLDOWN = 12\n",
    "SOFT_LAMBDA = 0.45\n",
    "E_MARGIN = 5.0    # extremely important for CCC dataset\n",
    "\n",
    "MODEL_LIST = [\n",
    "    (\"RDumbPP\", \"rdumbpp_ent_soft\")\n",
    "]\n",
    "\n",
    "dataset_name = \"baseline_20_transition+speed_1000_seed_43\"\n",
    "\n",
    "################################################################################\n",
    "#   Helper: Loader\n",
    "################################################################################\n",
    "def get_loader(dset_name, batch_size=64, max_images=10000):\n",
    "    import webdataset as wds\n",
    "    import torchvision.transforms as trn\n",
    "    \n",
    "    url = f'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/{dset_name}/serial_{{00000..99999}}.tar'\n",
    "\n",
    "    normalize = trn.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "    preproc = trn.Compose([trn.ToTensor(), normalize])\n",
    "\n",
    "    dataset = (\n",
    "        wds.WebDataset(url)\n",
    "        .decode(\"pil\")\n",
    "        .to_tuple(\"input.jpg\", \"output.cls\")\n",
    "        .map_tuple(preproc, lambda x: x)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "    return loader\n",
    "\n",
    "################################################################################\n",
    "#   Helper: Evaluate model\n",
    "################################################################################\n",
    "def eval_model(model, dname):\n",
    "    loader = get_loader(dname)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "\n",
    "    # Track adaptation\n",
    "    ent_history = []\n",
    "    drift_history = []\n",
    "    reset_history = []\n",
    "\n",
    "    for step, (images, labels) in enumerate(loader):\n",
    "        if total_seen >= 10000:\n",
    "            break\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass (RDumb++ automatically adapts)\n",
    "        outputs = model(images)\n",
    "\n",
    "        preds = outputs.argmax(1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_seen += images.size(0)\n",
    "\n",
    "        # Track entropy\n",
    "        probs = outputs.softmax(1)\n",
    "        batch_ent = -(probs * probs.log()).sum(1).mean().item()\n",
    "        ent_history.append(batch_ent)\n",
    "\n",
    "        # If RDumb++ tracked drift\n",
    "        if hasattr(model, \"last_drift\"):\n",
    "            drift_history.append(model.last_drift)\n",
    "            reset_history.append(model.last_reset)\n",
    "        else:\n",
    "            drift_history.append(None)\n",
    "            reset_history.append(False)\n",
    "\n",
    "    acc = 100 * total_correct / total_seen\n",
    "    return acc, ent_history, drift_history, reset_history\n",
    "\n",
    "################################################################################\n",
    "#   RUN COMPARISON\n",
    "################################################################################\n",
    "print(\"\\n=======================================================\")\n",
    "print(\"RUNNING RDumb vs RDumb++ COMPARISON\")\n",
    "print(\"=======================================================\\n\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, mode in MODEL_LIST:\n",
    "    print(f\"\\n----- Initializing {name} -----\")\n",
    "\n",
    "    base = tv_models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    # if mode == \"rdumb\":\n",
    "    #     model = registery.init(mode, base)\n",
    "\n",
    "    if mode == \"rdumbpp_ent_soft\":\n",
    "        model = registery.init(\n",
    "            mode,\n",
    "            base,\n",
    "            drift_k=DRIFT_K,\n",
    "            warmup_steps=WARMUP,\n",
    "            cooldown_steps=COOLDOWN,\n",
    "            soft_lambda=SOFT_LAMBDA,\n",
    "            entropy_ema_alpha=EMA_ALPHA,\n",
    "            kl_ema_alpha=EMA_ALPHA\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "\n",
    "    print(f\"â†’ Evaluating {name} on CCC-medium...\")\n",
    "    acc, ents, drifts, resets = eval_model(model, dataset_name)\n",
    "    results[name] = acc\n",
    "\n",
    "    print(f\"âœ“ {name}: {acc:.2f}%\")\n",
    "    print(f\"  resets   = {sum(resets)}\")\n",
    "    print(f\"  drift>0  = {sum(1 for d in drifts if d and d>0)}\")\n",
    "    print(f\"  last 5 entropy = {ents[-5:]}\")\n",
    "\n",
    "print(\"\\n=======================================================\")\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=======================================================\\n\")\n",
    "\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name:10s}: {acc:.2f}%\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
