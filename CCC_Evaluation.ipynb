{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1819e31",
   "metadata": {},
   "source": [
    "# CCC (Continuously Changing Corruptions) Evaluation Notebook\n",
    "\n",
    "This notebook sets up the CCC repository, installs dependencies, and runs evaluations for test-time adaptation models.\n",
    "\n",
    "## Python Version Requirements\n",
    "\n",
    "**Recommended: Python 3.9 or 3.10**\n",
    "\n",
    "The code uses:\n",
    "- f-strings (Python 3.6+)\n",
    "- Type hints (Python 3.5+)\n",
    "- PyTorch 1.9+ (supports Python 3.6-3.10)\n",
    "\n",
    "**Best choice: Python 3.9 or 3.10** for optimal compatibility with PyTorch and all dependencies.\n",
    "\n",
    "## Overview\n",
    "- Check Python version\n",
    "- Clone the CCC repository\n",
    "- Install required dependencies (with compatible versions)\n",
    "- Run evaluations for different models and configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0151b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.19\n",
      "Python version info: 3.10.19 (main, Oct 21 2025, 16:37:10) [Clang 20.1.8 ]\n",
      "âœ“ Python version is compatible (3.9+ recommended)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "python_version = sys.version_info\n",
    "print(f\"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "print(f\"Python version info: {sys.version}\")\n",
    "\n",
    "# Check if Python version is compatible\n",
    "if python_version.major == 3 and python_version.minor >= 8:\n",
    "    if python_version.minor >= 9:\n",
    "        print(\"âœ“ Python version is compatible (3.9+ recommended)\")\n",
    "    else:\n",
    "        print(\"âš  Python 3.8 detected. Python 3.9 or 3.10 is recommended for best compatibility.\")\n",
    "else:\n",
    "    print(\"âœ— Python version may not be compatible. Please use Python 3.8 or higher (3.9-3.10 recommended).\")\n",
    "    print(\"  The code requires Python 3.6+ but PyTorch works best with Python 3.8-3.10.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658c523",
   "metadata": {},
   "source": [
    "## Clone Repository\n",
    "\n",
    "Clone the CCC repository if not already present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists at /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC\n",
      "Current directory: /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC\n",
      "Repository path: /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC\n"
     ]
    }
   ],
   "source": [
    "# Check if repository is already cloned, if not clone it\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Determine the base directory (where the notebook is located)\n",
    "base_dir = os.getcwd()\n",
    "# If we're already in CCC directory, go up one level\n",
    "if os.path.basename(base_dir) == \"CCC\":\n",
    "    base_dir = os.path.dirname(base_dir)\n",
    "\n",
    "repo_name = \"CCC\"\n",
    "repo_path = os.path.join(base_dir, repo_name)\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"Cloning CCC repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/oripress/CCC.git\"], cwd=base_dir, check=True)\n",
    "    print(\"Repository cloned successfully!\")\n",
    "else:\n",
    "    print(f\"Repository already exists at {repo_path}\")\n",
    "\n",
    "# Change to the CCC directory for running evaluations\n",
    "os.chdir(repo_path)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Repository path: {repo_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521c81d",
   "metadata": {},
   "source": [
    "## ðŸ”§ GPU Setup and Installation\n",
    "\n",
    "**âš  IMPORTANT: This notebook must run on RunPod, not your local Mac!**\n",
    "\n",
    "**You're currently running on:** Your local Mac (no GPU support)  \n",
    "**You need to run on:** RunPod server (has GPU)\n",
    "\n",
    "### Option 1: Run Jupyter on RunPod (RECOMMENDED)\n",
    "\n",
    "1. **SSH into RunPod:**\n",
    "   ```bash\n",
    "   ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\n",
    "   ```\n",
    "\n",
    "2. **On RunPod, install Jupyter:**\n",
    "   ```bash\n",
    "   pip install jupyter notebook\n",
    "   ```\n",
    "\n",
    "3. **Start Jupyter on RunPod:**\n",
    "   ```bash\n",
    "   jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root\n",
    "   ```\n",
    "\n",
    "4. **Access from your Mac:**\n",
    "   - Copy the URL with token from RunPod terminal\n",
    "   - Or use port forwarding: `ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io`\n",
    "   - Then open `http://localhost:8888` in your browser\n",
    "\n",
    "### Option 2: Use RunPod's Built-in Jupyter\n",
    "\n",
    "If RunPod has Jupyter pre-installed, access it through RunPod's web interface.\n",
    "\n",
    "**Then run the cell below on RunPod to setup GPU.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU SETUP AND VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "[Step 0] System Check...\n",
      "  System: Darwin\n",
      "  Hostname: dhcp-128-189-237-153.ubcsecure.wireless.ubc.ca\n",
      "  Python: /Users/himanshumishra/miniconda3/envs/py310/bin/python\n",
      "\n",
      "======================================================================\n",
      "âš  WARNING: You're running on your LOCAL MAC!\n",
      "======================================================================\n",
      "\n",
      "Macs don't support CUDA/GPU. You need to run this on RunPod!\n",
      "\n",
      "To fix this:\n",
      "  1. SSH into RunPod:\n",
      "     ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\n",
      "\n",
      "  2. On RunPod, start Jupyter:\n",
      "     pip install jupyter\n",
      "     jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\n",
      "\n",
      "  3. Access from your Mac using port forwarding:\n",
      "     ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\n",
      "     Then open http://localhost:8888 in browser\n",
      "\n",
      "  4. Upload this notebook to RunPod and run it there\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot install CUDA PyTorch on Mac. Please run on RunPod.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  4. Upload this notebook to RunPod and run it there\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot install CUDA PyTorch on Mac. Please run on RunPod.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 1: Check GPU Hardware\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Step 1] Checking GPU Hardware...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot install CUDA PyTorch on Mac. Please run on RunPod."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SINGLE CELL: GPU Setup and Verification\n",
    "# This cell handles everything needed to connect to GPU\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU SETUP AND VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 0: Check if running on correct system\n",
    "print(\"\\n[Step 0] System Check...\")\n",
    "system = platform.system()\n",
    "hostname = platform.node()\n",
    "python_path = sys.executable\n",
    "\n",
    "print(f\"  System: {system}\")\n",
    "print(f\"  Hostname: {hostname}\")\n",
    "print(f\"  Python: {python_path}\")\n",
    "\n",
    "# Check if running on Mac (local) vs Linux (RunPod)\n",
    "if system == \"Darwin\" or \"miniconda3\" in python_path or \"Users\" in python_path:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âš  WARNING: You're running on your LOCAL MAC!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nMacs don't support CUDA/GPU. You need to run this on RunPod!\")\n",
    "    print(\"\\nTo fix this:\")\n",
    "    print(\"  1. SSH into RunPod:\")\n",
    "    print(\"     ssh -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
    "    print(\"\\n  2. On RunPod, start Jupyter:\")\n",
    "    print(\"     pip install jupyter\")\n",
    "    print(\"     jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser\")\n",
    "    print(\"\\n  3. Access from your Mac using port forwarding:\")\n",
    "    print(\"     ssh -L 8888:localhost:8888 -i ~/.ssh/runpod_key eqdlc2mhm8ogbt-64411dd7@ssh.runpod.io\")\n",
    "    print(\"     Then open http://localhost:8888 in browser\")\n",
    "    print(\"\\n  4. Upload this notebook to RunPod and run it there\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"Cannot install CUDA PyTorch on Mac. Please run on RunPod.\")\n",
    "\n",
    "# Step 1: Check GPU Hardware\n",
    "print(\"\\n[Step 1] Checking GPU Hardware...\")\n",
    "try:\n",
    "    result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,driver_version\", \"--format=csv,noheader\"], \n",
    "                           capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        gpu_info = result.stdout.strip().split('\\n')[0]\n",
    "        print(f\"  âœ“ GPU detected: {gpu_info}\")\n",
    "        gpu_available = True\n",
    "    else:\n",
    "        print(\"  âš  nvidia-smi not available\")\n",
    "        gpu_available = False\n",
    "except Exception as e:\n",
    "    print(f\"  âš  Could not check GPU: {e}\")\n",
    "    gpu_available = False\n",
    "\n",
    "# Step 2: Check Python Environment\n",
    "print(f\"\\n[Step 2] Python Environment:\")\n",
    "print(f\"  Python: {sys.executable}\")\n",
    "print(f\"  Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Step 3: Check Current PyTorch Installation\n",
    "print(f\"\\n[Step 3] Checking Current PyTorch Installation...\")\n",
    "need_install = False  # Initialize variable\n",
    "torch_installed = False\n",
    "cuda_available = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch_installed = True\n",
    "    print(f\"  âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  âœ“ PyTorch location: {torch.__file__}\")\n",
    "    \n",
    "    # Check for CUDA version mismatch\n",
    "    try:\n",
    "        import torchvision\n",
    "        print(f\"  âœ“ Torchvision version: {torchvision.__version__}\")\n",
    "        \n",
    "        # Try to check CUDA versions\n",
    "        try:\n",
    "            torch_cuda = torch.version.cuda if torch.cuda.is_available() else None\n",
    "            # This might raise an error if versions don't match\n",
    "            cuda_available = torch.cuda.is_available()\n",
    "            \n",
    "            if cuda_available:\n",
    "                print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "                print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                \n",
    "                # Test if there's a version mismatch by trying to use torchvision\n",
    "                try:\n",
    "                    # This will fail if versions don't match\n",
    "                    test_img = torchvision.transforms.ToTensor()(torch.zeros(3, 224, 224))\n",
    "                    print(\"\\n\" + \"=\"*70)\n",
    "                    print(\"ðŸŽ‰ SUCCESS! GPU is already working!\")\n",
    "                    print(\"=\"*70)\n",
    "                    print(\"\\nYou can proceed with evaluation. No installation needed.\")\n",
    "                    need_install = False\n",
    "                except RuntimeError as e:\n",
    "                    if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
    "                        print(\"  âš  CUDA version mismatch detected!\")\n",
    "                        print(f\"  Error: {e}\")\n",
    "                        print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
    "                        need_install = True\n",
    "                    else:\n",
    "                        raise\n",
    "            else:\n",
    "                print(\"  âš  CUDA not available - need to install CUDA PyTorch\")\n",
    "                need_install = True\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA versions\" in str(e) or \"different CUDA versions\" in str(e):\n",
    "                print(\"  âš  CUDA version mismatch detected!\")\n",
    "                print(f\"  Error: {e}\")\n",
    "                print(\"  Need to reinstall torchvision to match PyTorch CUDA version\")\n",
    "                need_install = True\n",
    "            else:\n",
    "                print(f\"  âš  Error checking CUDA: {e}\")\n",
    "                need_install = True\n",
    "    except ImportError:\n",
    "        print(\"  âš  Torchvision not installed\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"  PyTorch has CUDA but torchvision missing - will install\")\n",
    "            need_install = True\n",
    "        else:\n",
    "            need_install = True\n",
    "            \n",
    "except ImportError:\n",
    "    print(\"  âš  PyTorch not installed\")\n",
    "    need_install = True\n",
    "    torch_installed = False\n",
    "\n",
    "# Step 4: Install CUDA PyTorch if needed\n",
    "if need_install:\n",
    "    print(f\"\\n[Step 4] Installing CUDA-enabled PyTorch...\")\n",
    "    print(\"  This will install PyTorch 2.0.1 with CUDA 11.8 support\")\n",
    "    print(\"  (CUDA 11.8 is compatible with CUDA 12.x systems)\")\n",
    "    \n",
    "    # Uninstall existing PyTorch first\n",
    "    if torch_installed:\n",
    "        print(\"  Uninstalling existing PyTorch...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                      check=False, capture_output=True)\n",
    "    \n",
    "    # Install NumPy first (required)\n",
    "    print(\"  Installing NumPy < 2.0...\")\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"], \n",
    "                      check=True, capture_output=True, timeout=60)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check if we just need to fix torchvision version mismatch\n",
    "    if torch_installed and cuda_available:\n",
    "        print(\"  Fixing CUDA version mismatch...\")\n",
    "        print(\"  Reinstalling torchvision to match PyTorch CUDA version...\")\n",
    "        try:\n",
    "            # Uninstall torchvision first\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torchvision\", \"-y\", \"-q\"], \n",
    "                          check=False, capture_output=True)\n",
    "            # Reinstall torchvision matching PyTorch's CUDA version\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
    "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=300\n",
    "            )\n",
    "            print(\"    âœ“ Torchvision reinstalled successfully!\")\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f\"    âœ— Failed to fix version mismatch: {str(e)[:100]}\")\n",
    "            print(\"    Will try full reinstall...\")\n",
    "            success = False\n",
    "    else:\n",
    "        success = False\n",
    "    \n",
    "    # Install CUDA PyTorch - try multiple methods\n",
    "    if not success:\n",
    "        print(\"  Installing PyTorch with CUDA 11.8...\")\n",
    "        \n",
    "        # Method 1: Using --index-url (recommended)\n",
    "        try:\n",
    "            print(\"    Trying method 1: --index-url...\")\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
    "                 \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=600\n",
    "            )\n",
    "            print(\"    âœ“ Installation successful!\")\n",
    "            success = True\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"    âœ— Timeout - trying alternative method...\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "            print(\"    Trying alternative method...\")\n",
    "        \n",
    "        # Method 2: Using extra-index-url\n",
    "        if not success:\n",
    "            try:\n",
    "                print(\"    Trying method 2: --extra-index-url...\")\n",
    "                result = subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\",\n",
    "                     \"--extra-index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=600\n",
    "                )\n",
    "                print(\"    âœ“ Installation successful!\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "        \n",
    "        # Method 3: Install separately to ensure matching versions\n",
    "        if not success:\n",
    "            print(\"    Trying method 3: Separate installation...\")\n",
    "            try:\n",
    "                # Install PyTorch first\n",
    "                subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\",\n",
    "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    timeout=300\n",
    "                )\n",
    "                # Then install matching torchvision\n",
    "                subprocess.run(\n",
    "                    [sys.executable, \"-m\", \"pip\", \"install\", \"torchvision==0.15.2\",\n",
    "                     \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                    timeout=300\n",
    "                )\n",
    "                print(\"    âœ“ Installation successful!\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(f\"    âœ— Failed: {str(e)[:100]}\")\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âš  INSTALLATION FAILED\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nPlease install manually in terminal:\")\n",
    "        print(f\"  {sys.executable} -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        print(\"\\nThen restart kernel and run this cell again.\")\n",
    "        raise RuntimeError(\"CUDA PyTorch installation failed\")\n",
    "    \n",
    "    print(\"\\n  âœ“ CUDA PyTorch installed successfully!\")\n",
    "    print(\"  âš  IMPORTANT: Restarting kernel to load new PyTorch...\")\n",
    "    print(\"  (You may need to manually restart: Kernel â†’ Restart)\")\n",
    "\n",
    "# Step 5: Final Verification\n",
    "print(f\"\\n[Step 5] Final GPU Verification...\")\n",
    "print(\"  (If you just installed, restart kernel first!)\")\n",
    "\n",
    "try:\n",
    "    # Force reload if just installed\n",
    "    if need_install:\n",
    "        import importlib\n",
    "        if 'torch' in sys.modules:\n",
    "            importlib.reload(sys.modules['torch'])\n",
    "    \n",
    "    import torch\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    if cuda_available:\n",
    "        print(f\"  âœ“ CUDA available: True\")\n",
    "        print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  âœ“ Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        # Test GPU with actual computation\n",
    "        try:\n",
    "            print(\"  Testing GPU computation...\")\n",
    "            test_tensor = torch.randn(100, 100).cuda()\n",
    "            result = test_tensor @ test_tensor\n",
    "            print(\"  âœ“ GPU computation test: SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— GPU computation test failed: {e}\")\n",
    "            raise\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸŽ‰ SUCCESS! GPU IS FULLY CONNECTED AND WORKING!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nâœ“ GPU hardware detected\")\n",
    "        print(\"âœ“ CUDA PyTorch installed\")\n",
    "        print(\"âœ“ GPU computation verified\")\n",
    "        print(\"\\nYou can now proceed with evaluation cells.\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"  âœ— CUDA still not available\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"âš  GPU NOT DETECTED\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(\"  1. Kernel not restarted after installation\")\n",
    "        print(\"     â†’ Go to: Kernel â†’ Restart & Clear Output\")\n",
    "        print(\"     â†’ Then run this cell again\")\n",
    "        print(\"\\n  2. Python environment mismatch\")\n",
    "        print(f\"     â†’ Terminal Python: Check with 'which python3'\")\n",
    "        print(f\"     â†’ Notebook Python: {sys.executable}\")\n",
    "        print(\"     â†’ They should match!\")\n",
    "        print(\"\\n  3. CUDA libraries not found\")\n",
    "        print(\"     â†’ Check: ls /usr/local/cuda*/lib64\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error during verification: {e}\")\n",
    "    print(\"\\nPlease restart kernel and run this cell again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d2d12",
   "metadata": {},
   "source": [
    "## âš  IMPORTANT: GPU Detection\n",
    "\n",
    "**If you installed CUDA PyTorch in the terminal, you MUST restart the Jupyter kernel!**\n",
    "\n",
    "The kernel needs to be restarted to load the new CUDA-enabled PyTorch. Otherwise, it will still use the old CPU version that was loaded into memory.\n",
    "\n",
    "**To restart:** Go to `Kernel` â†’ `Restart` (or `Restart & Clear Output`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GPU/CUDA status and Python environment...\n",
      "============================================================\n",
      "Python Environment:\n",
      "  Python executable: /Users/himanshumishra/miniconda3/envs/py310/bin/python\n",
      "  Python version: 3.10.19\n",
      "  Python path: /Users/himanshumishra/miniconda3/envs/py310/bin/python\n",
      "  Pip: pip 25.2 from /Users/himanshumishra/miniconda3/envs/py310/lib/python3.10/site-packages/pip (python 3.10)\n",
      "\n",
      "GPU Hardware Check:\n",
      "  âš  nvidia-smi not available\n",
      "\n",
      "PyTorch Installation:\n",
      "  âœ“ PyTorch version: 2.0.1\n",
      "  âœ“ PyTorch location: /Users/himanshumishra/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\n",
      "  âœ“ CUDA available: False\n",
      "\n",
      "============================================================\n",
      "âš  WARNING: CUDA is NOT available in this kernel!\n",
      "============================================================\n",
      "\n",
      "Diagnostics:\n",
      "  - PyTorch location: /Users/himanshumishra/miniconda3/envs/py310/lib/python3.10/site-packages/torch/__init__.py\n",
      "  - Python executable: /Users/himanshumishra/miniconda3/envs/py310/bin/python\n",
      "\n",
      "Checking CUDA libraries...\n",
      "  âš  CUDA library paths not found\n",
      "\n",
      "Possible solutions:\n",
      "  1. Make sure you installed CUDA PyTorch in the SAME Python environment\n",
      "     Terminal Python: Check with 'which python3' in terminal\n",
      "     Notebook Python: /Users/himanshumishra/miniconda3/envs/py310/bin/python\n",
      "     They should match!\n",
      "\n",
      "  2. If Python paths don't match:\n",
      "     - Install CUDA PyTorch using the notebook's Python:\n",
      "       /Users/himanshumishra/miniconda3/envs/py310/bin/python -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
      "\n",
      "  3. Or restart kernel and run installation cell\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA PyTorch is installed and GPU is detected\n",
    "# Run this cell AFTER restarting the kernel if you installed CUDA PyTorch in terminal\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"Checking GPU/CUDA status and Python environment...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check Python environment\n",
    "print(\"Python Environment:\")\n",
    "print(f\"  Python executable: {sys.executable}\")\n",
    "print(f\"  Python version: {sys.version.split()[0]}\")\n",
    "print(f\"  Python path: {sys.executable}\")\n",
    "\n",
    "# Check which pip is being used\n",
    "try:\n",
    "    pip_result = subprocess.run([sys.executable, \"-m\", \"pip\", \"--version\"], \n",
    "                               capture_output=True, text=True, timeout=5)\n",
    "    print(f\"  Pip: {pip_result.stdout.strip()}\")\n",
    "except:\n",
    "    print(\"  âš  Could not check pip version\")\n",
    "\n",
    "# Check nvidia-smi\n",
    "print(\"\\nGPU Hardware Check:\")\n",
    "try:\n",
    "    nvidia_result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"], \n",
    "                                   capture_output=True, text=True, timeout=5)\n",
    "    if nvidia_result.returncode == 0:\n",
    "        gpu_name = nvidia_result.stdout.strip().split('\\n')[0]\n",
    "        print(f\"  âœ“ GPU detected: {gpu_name}\")\n",
    "    else:\n",
    "        print(\"  âš  nvidia-smi not available\")\n",
    "except:\n",
    "    print(\"  âš  nvidia-smi not available\")\n",
    "\n",
    "# Check PyTorch installation\n",
    "print(\"\\nPyTorch Installation:\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"  âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  âœ“ PyTorch location: {torch.__file__}\")\n",
    "    \n",
    "    # Check if it's CPU or CUDA build\n",
    "    print(f\"  âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  âœ“ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"  âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  âœ“ Number of GPUs: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        # Test GPU with a simple operation\n",
    "        try:\n",
    "            test_tensor = torch.randn(10, 10).cuda()\n",
    "            _ = test_tensor @ test_tensor\n",
    "            print(\"  âœ“ GPU test: SUCCESS\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— GPU test failed: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸŽ‰ SUCCESS! GPU is detected and ready to use!\")\n",
    "        print(\"You can proceed with the evaluation cells.\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âš  WARNING: CUDA is NOT available in this kernel!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nDiagnostics:\")\n",
    "        print(f\"  - PyTorch location: {torch.__file__}\")\n",
    "        print(f\"  - Python executable: {sys.executable}\")\n",
    "        \n",
    "        # Check if CUDA libraries are available\n",
    "        print(\"\\nChecking CUDA libraries...\")\n",
    "        cuda_lib_paths = [\n",
    "            \"/usr/local/cuda/lib64\",\n",
    "            \"/usr/lib/x86_64-linux-gnu\",\n",
    "            \"/usr/local/cuda-11.8/lib64\",\n",
    "            \"/usr/local/cuda-12.1/lib64\",\n",
    "        ]\n",
    "        cuda_found = False\n",
    "        for path in cuda_lib_paths:\n",
    "            if os.path.exists(path):\n",
    "                print(f\"  âœ“ Found CUDA path: {path}\")\n",
    "                cuda_found = True\n",
    "        if not cuda_found:\n",
    "            print(\"  âš  CUDA library paths not found\")\n",
    "        \n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"  1. Make sure you installed CUDA PyTorch in the SAME Python environment\")\n",
    "        print(f\"     Terminal Python: Check with 'which python3' in terminal\")\n",
    "        print(f\"     Notebook Python: {sys.executable}\")\n",
    "        print(\"     They should match!\")\n",
    "        print(\"\\n  2. If Python paths don't match:\")\n",
    "        print(\"     - Install CUDA PyTorch using the notebook's Python:\")\n",
    "        print(f\"       {sys.executable} -m pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        print(\"\\n  3. Or restart kernel and run installation cell\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"  âœ— PyTorch is not installed\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Please run the installation cell first.\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889cc38",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install all required packages with compatible versions. **Important**: We need NumPy < 2.0 for compatibility with torchvision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34848a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies with CUDA support for GPU...\n",
      "============================================================\n",
      "âš  GPU not detected via nvidia-smi\n",
      "  Will still attempt CUDA installation - PyTorch will detect GPU if available\n",
      "\n",
      "Step 1: Cleaning up existing installations...\n",
      "  âœ“ Cleaned up existing installations\n",
      "\n",
      "Step 2: Installing NumPy < 2.0 (required for compatibility)...\n",
      "  âœ“ NumPy < 2.0 installed\n",
      "\n",
      "Step 3: Installing PyTorch and torchvision with CUDA support...\n",
      "  Trying CUDA 12.1 first (for CUDA 12.x systems like RunPod)...\n",
      "  âš  Error with CUDA 12.1, trying CUDA 11.8...\n",
      "  âš  Trying CPU version as fallback...\n",
      "  âœ“ PyTorch 2.0.1 and torchvision 0.15.2 installed (CPU version)\n",
      "  âš  WARNING: CPU version installed. GPU will not be available!\n",
      "\n",
      "Step 4: Installing other dependencies...\n",
      "  Installing webdataset>=0.2.0...\n",
      "  âœ“ webdataset>=0.2.0 installed\n",
      "  Installing Pillow>=8.0.0...\n",
      "  âœ“ Pillow>=8.0.0 installed\n",
      "\n",
      "============================================================\n",
      "Dependency installation completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies with compatible versions\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing dependencies with compatible versions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# First, uninstall existing packages to avoid conflicts\n",
    "print(\"Step 1: Cleaning up existing installations...\")\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"numpy\", \"-y\", \"-q\"], \n",
    "                  check=False, capture_output=True)\n",
    "    print(\"  âœ“ Cleaned up existing installations\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Install NumPy first (must be < 2.0 for compatibility)\n",
    "print(\"\\nStep 2: Installing NumPy < 2.0 (required for compatibility)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"numpy<2.0\", \"-q\"],\n",
    "        check=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(\"  âœ“ NumPy < 2.0 installed\")\n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error installing NumPy: {e}\")\n",
    "\n",
    "# Install PyTorch and torchvision together with compatible versions\n",
    "print(\"\\nStep 3: Installing PyTorch and torchvision (compatible versions)...\")\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"torch==2.0.1\", \"torchvision==0.15.2\", \"-q\"],\n",
    "        check=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    print(\"  âœ“ PyTorch 2.0.1 and torchvision 0.15.2 installed successfully\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"  âš  Error with specific versions, trying compatible range...\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"torch>=2.0.0,<2.1.0\", \"torchvision>=0.15.0,<0.16.0\", \"-q\"],\n",
    "            check=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"  âœ“ PyTorch and torchvision installed (compatible versions)\")\n",
    "    except:\n",
    "        print(\"  âœ— Failed to install PyTorch/torchvision\")\n",
    "        raise\n",
    "\n",
    "# Install other dependencies\n",
    "print(\"\\nStep 4: Installing other dependencies...\")\n",
    "other_packages = [\n",
    "    \"webdataset>=0.2.0\",\n",
    "    \"Pillow>=8.0.0\",\n",
    "]\n",
    "\n",
    "for package in other_packages:\n",
    "    print(f\"  Installing {package}...\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"],\n",
    "            check=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(f\"  âœ“ {package} installed\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"  âœ— Error installing {package}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dependency installation completed!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a31e2f",
   "metadata": {},
   "source": [
    "## Verify Installations\n",
    "\n",
    "Check that all packages are installed correctly and are compatible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f83141",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2bdff3",
   "metadata": {},
   "source": [
    "## Create Logs Directory\n",
    "\n",
    "Create directory for storing evaluation results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc8c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs directory already exists: logs\n",
      "Created dataset directory: ccc_datasets\n",
      "\n",
      "Dataset will be stored at: /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC/ccc_datasets\n",
      "Logs will be stored at: /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC/logs\n"
     ]
    }
   ],
   "source": [
    "# Verify installations and compatibility\n",
    "print(\"Verifying installations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— PyTorch not installed: {e}\")\n",
    "    torch = None\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    print(f\"âœ“ Torchvision version: {torchvision.__version__}\")\n",
    "    \n",
    "    # Test compatibility by importing models\n",
    "    try:\n",
    "        import torchvision.models as models\n",
    "        print(\"âœ“ Torchvision models import successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Torchvision compatibility issue: {e}\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Torchvision not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    print(f\"âœ“ NumPy version: {numpy.__version__}\")\n",
    "    if numpy.__version__.startswith(\"2.\"):\n",
    "        print(\"  âš  WARNING: NumPy 2.x detected. This may cause compatibility issues.\")\n",
    "        print(\"  Please downgrade to NumPy < 2.0 by running: pip install 'numpy<2.0'\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— NumPy not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import webdataset\n",
    "    print(f\"âœ“ WebDataset version: {webdataset.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— WebDataset not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import PIL\n",
    "    print(f\"âœ“ Pillow version: {PIL.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âœ— Pillow not installed: {e}\")\n",
    "\n",
    "if torch is not None:\n",
    "    print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"âš  CUDA not available. GPU acceleration will not be used.\")\n",
    "        print(\"  Note: The evaluation can run on CPU but will be VERY slow.\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f7fe8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43554fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 9 dataset configurations...\n",
      "Baseline: 20 (CCC-Medium)\n",
      "Storage location: /Users/himanshumishra/Library/CloudStorage/OneDrive-UBC/UBC/Term1/ProjectAdaptive/CCC/ccc_datasets\n",
      "============================================================\n",
      "Note: This will download the dataset files. The dataset is large and may take time.\n",
      "You can skip this step and use streaming if you prefer (slower but no download needed).\n",
      "============================================================\n",
      "\n",
      "[1/9] Downloading: baseline_20_transition+speed_1000_seed_43\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m cmd_base \u001b[38;5;241m+\u001b[39m [local_path, url]\n\u001b[0;32m---> 65\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Check if file was actually downloaded (not empty)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_path) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(local_path) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create logs directory\n",
    "import os\n",
    "\n",
    "logs_dir = \"logs\"\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    print(f\"Created logs directory: {logs_dir}\")\n",
    "else:\n",
    "    print(f\"Logs directory already exists: {logs_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054e12f",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Stream datasets from cloud (no local download needed)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "- **Run all computations on GPU** (requires CUDA)\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). \n",
    "\n",
    "**GPU Performance**: With GPU, each evaluation should complete in a reasonable time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acab1f3",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Use locally stored datasets (downloaded in previous step)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). \n",
    "\n",
    "**GPU Performance**: With GPU, each evaluation should complete in a reasonable time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc852049",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "Run evaluations for different models. The evaluation will:\n",
    "- Use streaming datasets (no local download needed)\n",
    "- Evaluate on different baseline accuracies (0, 20, 40)\n",
    "- Test different models (rdumb, tent, pretrained, etc.)\n",
    "\n",
    "**Note**: Each evaluation processes 9 runs (3 seeds Ã— 3 transition speeds). This may take some time.\n",
    "\n",
    "**Important**: \n",
    "- The evaluation can run on CPU but will be VERY slow (may take days)\n",
    "- For reasonable performance, use a system with GPU and CUDA installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b47bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for mode: rdumb, baseline: 20\n",
      "This will evaluate all 9 configurations (3 seeds Ã— 3 speeds)\n",
      "Note: This may take a while as it processes the entire dataset...\n",
      "âš  WARNING: If running on CPU, this may take days to complete!\n",
      "\n",
      "============================================================\n",
      "\n",
      "Running evaluation 1/9 (processind=0)\n",
      "------------------------------------------------------------\n",
      "âœ— Error in processind 0\n",
      "Error output (last 500 chars):\n",
      " in read\n",
      "    raise ReadError(\"unexpected end of data\")\n",
      "tarfile.ReadError: (\"unexpected end of data @ <Pipe ((['curl', '--connect-timeout', '30', '--retry', '30', '--retry-delay', '2', '-f', '-s', '-L', 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_1000_seed_43/serial_00000.tar'],), {'bufsize': 8192})>\", <webdataset.gopen.Pipe object at 0x13d140400>, 'https://mlcloud.uni-tuebingen.de:7443/datasets/CCC/baseline_20_transition+speed_1000_seed_43/serial_00000.tar')\n",
      "\n",
      "\n",
      "Running evaluation 2/9 (processind=1)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(55131) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m\n\u001b[1;32m     30\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--dset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Empty since we're using streaming\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ“ Completed processind \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;66;03m# Only print last few lines to avoid clutter\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run evaluation for RDumb model (the paper's main contribution)\n",
    "# This will evaluate on baseline 20 (CCC-Medium) with all 9 configurations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure we're in the CCC directory\n",
    "if not os.path.exists(\"eval.py\"):\n",
    "    print(\"Error: eval.py not found. Make sure you're in the CCC directory.\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "else:\n",
    "    # Configuration\n",
    "    mode = \"rdumb\"\n",
    "    baseline = 20  # CCC-Medium (0=Hard, 20=Medium, 40=Easy)\n",
    "    logs_path = \"logs\"\n",
    "\n",
    "    print(f\"Running evaluation for mode: {mode}, baseline: {baseline}\")\n",
    "    print(\"This will evaluate all 9 configurations (3 seeds Ã— 3 speeds)\")\n",
    "    print(\"Note: This may take a while as it processes the entire dataset...\")\n",
    "    print(\"âš  WARNING: If running on CPU, this may take days to complete!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    # Run evaluation for each of the 9 configurations\n",
    "    # processind 0-8 covers all combinations\n",
    "    for processind in range(9):\n",
    "        print(f\"\\nRunning evaluation {processind + 1}/9 (processind={processind})\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        cmd = [\n",
    "            sys.executable, \"eval.py\",\n",
    "            \"--mode\", mode,\n",
    "            \"--baseline\", str(baseline),\n",
    "            \"--logs\", logs_path,\n",
    "            \"--processind\", str(processind),\n",
    "            \"--dset\", \"\"  # Empty since we're using streaming\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=3600)\n",
    "            print(f\"âœ“ Completed processind {processind}\")\n",
    "            if result.stdout:\n",
    "                # Only print last few lines to avoid clutter\n",
    "                lines = result.stdout.strip().split('\\n')\n",
    "                if len(lines) > 5:\n",
    "                    print(\"  ... (output truncated) ...\")\n",
    "                    for line in lines[-3:]:\n",
    "                        print(f\"  {line}\")\n",
    "                else:\n",
    "                    print(result.stdout)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"âœ— Timeout for processind {processind} (took longer than 1 hour)\")\n",
    "            print(\"  This is normal for CPU execution. Consider using GPU for faster results.\")\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âœ— Error in processind {processind}\")\n",
    "            print(f\"Error output (last 500 chars):\")\n",
    "            error_msg = e.stderr if e.stderr else e.stdout\n",
    "            if error_msg:\n",
    "                print(error_msg[-500:])\n",
    "            else:\n",
    "                print(\"No error message available\")\n",
    "            # Don't break, continue with next processind\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Evaluation completed!\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all result files\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(result_files)} result files:\")\n",
    "    for f in sorted(result_files):\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "        \n",
    "    # Read and display a sample result file\n",
    "    if result_files:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Sample result file (first 20 lines):\")\n",
    "        print(\"=\"*60)\n",
    "        with open(result_files[0], 'r') as f:\n",
    "            lines = f.readlines()[:20]\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"{i:4d}: {line.strip()}\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average accuracy from result files\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calculate_avg_accuracy(result_file):\n",
    "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
    "    accuracies = []\n",
    "    with open(result_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('acc_'):\n",
    "                try:\n",
    "                    acc = float(line.split('_')[1])\n",
    "                    accuracies.append(acc)\n",
    "                except:\n",
    "                    pass\n",
    "    return np.mean(accuracies) if accuracies else None\n",
    "\n",
    "# Calculate averages for all result files\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    \n",
    "    print(\"Average Accuracies:\")\n",
    "    print(\"=\"*60)\n",
    "    for f in sorted(result_files):\n",
    "        avg_acc = calculate_avg_accuracy(f)\n",
    "        if avg_acc is not None:\n",
    "            filename = os.path.basename(f)\n",
    "            print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
    "    \n",
    "    # Overall average\n",
    "    all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
    "    all_accs = [a for a in all_accs if a is not None]\n",
    "    if all_accs:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
    "        print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbeee4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c01b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 result files:\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_43.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_44.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_1000_seed_45.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_2000_seed_43.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_2000_seed_44.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_2000_seed_45.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_5000_seed_43.txt\n",
      "  - model_rdumb_baseline_20_transition+speed_5000_seed_44.txt\n",
      "\n",
      "============================================================\n",
      "Sample result file (first 20 lines):\n",
      "============================================================\n",
      "   1: acc_28.1250000000\n",
      "   2: acc_29.6875000000\n",
      "   3: acc_32.8125000000\n",
      "   4: acc_25.0000000000\n",
      "   5: acc_29.6875000000\n",
      "   6: acc_29.6875000000\n",
      "   7: acc_34.3750000000\n",
      "   8: acc_23.4375000000\n",
      "   9: acc_34.3750000000\n",
      "  10: acc_25.0000000000\n",
      "  11: acc_23.4375000000\n",
      "  12: acc_34.3750000000\n",
      "  13: acc_31.2500000000\n",
      "  14: acc_26.5625000000\n",
      "  15: acc_40.6250000000\n",
      "  16: acc_34.3750000000\n",
      "  17: acc_29.6875000000\n",
      "  18: acc_29.6875000000\n",
      "  19: acc_48.4375000000\n",
      "  20: acc_37.5000000000\n"
     ]
    }
   ],
   "source": [
    "# List all result files\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(result_files)} result files:\")\n",
    "    for f in sorted(result_files):\n",
    "        print(f\"  - {os.path.basename(f)}\")\n",
    "        \n",
    "    # Read and display a sample result file\n",
    "    if result_files:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Sample result file (first 20 lines):\")\n",
    "        print(\"=\"*60)\n",
    "        with open(result_files[0], 'r') as f:\n",
    "            lines = f.readlines()[:20]\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"{i:4d}: {line.strip()}\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678187f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracies:\n",
      "============================================================\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_43.txt    32.1429%\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_44.txt    28.5156%\n",
      "model_rdumb_baseline_20_transition+speed_1000_seed_45.txt    28.5362%\n",
      "model_rdumb_baseline_20_transition+speed_2000_seed_43.txt    37.5615%\n",
      "model_rdumb_baseline_20_transition+speed_2000_seed_44.txt    25.1302%\n",
      "model_rdumb_baseline_20_transition+speed_2000_seed_45.txt    25.1302%\n",
      "model_rdumb_baseline_20_transition+speed_5000_seed_43.txt    40.3125%\n",
      "model_rdumb_baseline_20_transition+speed_5000_seed_44.txt    28.5156%\n",
      "============================================================\n",
      "Overall Average:                                             30.7306%\n",
      "Std Dev:                                                     5.2181%\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy from result files\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def calculate_avg_accuracy(result_file):\n",
    "    \"\"\"Calculate average accuracy from a result file.\"\"\"\n",
    "    accuracies = []\n",
    "    with open(result_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('acc_'):\n",
    "                try:\n",
    "                    acc = float(line.split('_')[1])\n",
    "                    accuracies.append(acc)\n",
    "                except:\n",
    "                    pass\n",
    "    return np.mean(accuracies) if accuracies else None\n",
    "\n",
    "# Calculate averages for all result files\n",
    "results_dir = os.path.join(\"logs\", \"ccc_20\")\n",
    "if os.path.exists(results_dir):\n",
    "    result_files = glob.glob(os.path.join(results_dir, \"*.txt\"))\n",
    "    \n",
    "    print(\"Average Accuracies:\")\n",
    "    print(\"=\"*60)\n",
    "    for f in sorted(result_files):\n",
    "        avg_acc = calculate_avg_accuracy(f)\n",
    "        if avg_acc is not None:\n",
    "            filename = os.path.basename(f)\n",
    "            print(f\"{filename:60s} {avg_acc:.4f}%\")\n",
    "    \n",
    "    # Overall average\n",
    "    all_accs = [calculate_avg_accuracy(f) for f in result_files]\n",
    "    all_accs = [a for a in all_accs if a is not None]\n",
    "    if all_accs:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"{'Overall Average:':60s} {np.mean(all_accs):.4f}%\")\n",
    "        print(f\"{'Std Dev:':60s} {np.std(all_accs):.4f}%\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
